{
 "cells": [
  {
   "cell_type": "raw",
   "id": "30d2b42b",
   "metadata": {},
   "source": [
    "# Task : Text Classification\n",
    "    Data : glue/mrpc \n",
    "        The General Language Understanding Evaluation benchmark/ \n",
    "        The Microsoft Research Paraphrase Corpus (Dolan & Brockett, 2005) is a corpus of sentence pairs automatically extracted from online news sources, with human annotations for whether the sentences in the pair are semantically equivalent.\n",
    "   Data Source : https://www.tensorflow.org/datasets/catalog/glue\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add03a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185c6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence warnings\n",
    "TOKENIZERS_PARALLELISM= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b1614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRCPDataLoader(pl.LightningDataModule):\n",
    "    def __init__(self,batch_size,checkpoint=\"bert-base-uncased\",num_workers=4):\n",
    "        super(MRCPDataLoader,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.checkpoint = checkpoint\n",
    "        self.tokenizer= AutoTokenizer.from_pretrained(self.checkpoint)\n",
    "        self.data_collector = DataCollatorWithPadding(self.tokenizer)\n",
    "        \n",
    "        \n",
    "    def prepare_data(self):\n",
    "        load_dataset('glue','mrpc')\n",
    "        \n",
    "\n",
    "    def _tokenizer_func(self,sample):\n",
    "        return self.tokenizer(sample['sentence1'],sample['sentence2'],truncation=True)\n",
    "\n",
    "\n",
    "    def setup(self, stage):\n",
    "        dataset = load_dataset('glue','mrpc')\n",
    "        tokenized_dataset = dataset.map(self._tokenizer_func,batched=True,batch_size=100)\n",
    "        data_collector = DataCollatorWithPadding(self.tokenizer)\n",
    "        \n",
    "        # Preprocessing \n",
    "        tokenized_dataset = tokenized_dataset.remove_columns(['sentence1', 'sentence2','idx'])  # remove text columns\n",
    "        tokenized_dataset = tokenized_dataset.rename_column('label','labels')\n",
    "        tokenized_dataset.set_format('torch')\n",
    "        \n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset=self.tokenized_dataset['train'],batch_size=self.batch_size,shuffle=True,num_workers=self.num_workers,collate_fn=self.data_collector)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset=self.tokenized_dataset['validation'],batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers,collate_fn=self.data_collector)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(dataset=self.tokenized_dataset['test'],batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers,collate_fn=self.data_collector)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60aa8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "ds = MRCPDataLoader(batch_size,checkpoint=checkpoint,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a011f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e01194d2efb4359918af88c7d7cf8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([10]),\n",
       " 'input_ids': torch.Size([10, 80]),\n",
       " 'token_type_ids': torch.Size([10, 80]),\n",
       " 'attention_mask': torch.Size([10, 80])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Inspecting\n",
    "ds.setup(stage='fit')\n",
    "for batch in ds.train_dataloader():\n",
    "    break\n",
    "    \n",
    "{k:v.shape for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b04033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a0441cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Inspect single training cycle \n",
    "model(**batch).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b489e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torchview import draw_graph\n",
    "\n",
    "# model_graph = draw_graph(model(),input_data=batch, expand_nested=True)\n",
    "# model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdaa5265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "/Users/pranavjha/Library/Caches/pypoetry/virtualenvs/applied-deeplearning-UPsxMYgd-py3.10/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">41</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'Loading model from checkpoints : '</span>,best_checkpoint_filename[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>])                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>trainer.fit(model, ds, ckpt_path=os.path.join(checkpoint_callback.dirpath, best_chec    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> :                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>41 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>trainer.fit(model,datamodule=ds)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">42 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">43 </span>trainer.validate(model, ds)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/pranavjha/Library/Caches/pypoetry/virtualenvs/applied-deeplearning-UPsxMYgd-py3.10/lib/py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">thon3.10/site-packages/lightning/pytorch/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">527</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 524 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 525 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">For more information about multiple dataloaders, see this :ref:`section &lt;multipl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 526 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 527 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model = _maybe_unwrap_optimized(model)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 528 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy._lightning_module = model                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_and_handle_interrupt(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/pranavjha/Library/Caches/pypoetry/virtualenvs/applied-deeplearning-UPsxMYgd-py3.10/lib/py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">thon3.10/site-packages/lightning/pytorch/utilities/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">compile.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">125</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_maybe_unwrap_optimized</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> from_compiled(model)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(model, pl.LightningModule):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>125 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `{</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got \n",
       "`BertForSequenceClassification`\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m41\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mLoading model from checkpoints : \u001b[0m\u001b[33m'\u001b[0m,best_checkpoint_filename[\u001b[94m0\u001b[0m])                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m39 \u001b[0m\u001b[2m│   \u001b[0mtrainer.fit(model, ds, ckpt_path=os.path.join(checkpoint_callback.dirpath, best_chec    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m40 \u001b[0m\u001b[94melse\u001b[0m :                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m41 \u001b[2m│   \u001b[0mtrainer.fit(model,datamodule=ds)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0mtrainer.validate(model, ds)                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/pranavjha/Library/Caches/pypoetry/virtualenvs/applied-deeplearning-UPsxMYgd-py3.10/lib/py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mthon3.10/site-packages/lightning/pytorch/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m527\u001b[0m in \u001b[92mfit\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 524 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 525 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mFor more information about multiple dataloaders, see this :ref:`section <multipl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 526 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 527 \u001b[2m│   │   \u001b[0mmodel = _maybe_unwrap_optimized(model)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 528 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy._lightning_module = model                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m│   │   \u001b[0mcall._call_and_handle_interrupt(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 530 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, \u001b[96mself\u001b[0m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/pranavjha/Library/Caches/pypoetry/virtualenvs/applied-deeplearning-UPsxMYgd-py3.10/lib/py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mthon3.10/site-packages/lightning/pytorch/utilities/\u001b[0m\u001b[1;33mcompile.py\u001b[0m:\u001b[94m125\u001b[0m in \u001b[92m_maybe_unwrap_optimized\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m from_compiled(model)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(model, pl.LightningModule):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m model                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m125 \u001b[2m│   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001b[0m\u001b[33m{\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got \n",
       "`BertForSequenceClassification`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir='./log/', name='mrpc', version=0.1)\n",
    "\n",
    "profiler = pl.profilers.PyTorchProfiler(\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/',),\n",
    "    schedule=torch.profiler.schedule(skip_first=10, wait=10, warmup=1, active=2)\n",
    ")\n",
    "\n",
    "# saves top-K checkpoints based on \"val_loss\" metric\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "#     save_last=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"max\",\n",
    "    dirpath=\"checkpoints/mrpc/\",\n",
    "    filename=\"{epoch}-{val_f1score:.3f}\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    accelerator='auto',\n",
    "    devices=[0],\n",
    "    min_epochs=1,\n",
    "    max_epochs=5,\n",
    "    precision='16-mixed',\n",
    "#     enable_model_summary=True,\n",
    "#     profiler=profiler,\n",
    "    callbacks=[checkpoint_callback,\n",
    "               pl.callbacks.EarlyStopping('val_loss',mode='min',patience=5,verbose=True,min_delta=0.00)],\n",
    "    enable_checkpointing  = True,\n",
    ")\n",
    "if os.path.exists(checkpoint_callback.dirpath):\n",
    "    best_checkpoint_filename = os.listdir(checkpoint_callback.dirpath)\n",
    "else: \n",
    "    best_checkpoint_filename = None\n",
    "\n",
    "if best_checkpoint_filename:\n",
    "    print('Loading model from checkpoints : ',best_checkpoint_filename[0])\n",
    "    trainer.fit(model, ds, ckpt_path=os.path.join(checkpoint_callback.dirpath, best_checkpoint_filename[0]))\n",
    "else : \n",
    "    trainer.fit(model,datamodule=ds)\n",
    "\n",
    "trainer.validate(model, ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363c46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Make it work with pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01c9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied-deeplearning",
   "language": "python",
   "name": "applied-deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
