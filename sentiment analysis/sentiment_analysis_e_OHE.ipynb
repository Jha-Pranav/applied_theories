{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sudo Code \n",
    "# Data : \n",
    "    \n",
    "# Method : \n",
    "# Word Embedding : One Hot Encoding\n",
    "    \n",
    "# observation\n",
    "# TODO : Optimize the network, validation loss increase with the decrease in the training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ce1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "import torchmetrics\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32833282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27480 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27480 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27480 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "df = pd.read_csv('data/Tweets.csv').dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9b44f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b86ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textID           0\n",
      "text             0\n",
      "selected_text    0\n",
      "sentiment        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "# drop nan\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5210452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label target class\n",
    "cat_id = {'neutral': 0, \n",
    "          'negative': 2, \n",
    "          'positive': 1}\n",
    "\n",
    "df['class'] = df['sentiment'].map(cat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e783355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n",
    "\n",
    "class TweetDataLoader(pl.LightningDataModule):\n",
    "    def __init__(self, df, batch_size, num_workers=4):\n",
    "        super(TweetDataLoader, self).__init__()\n",
    "        self.data = df['text'].values\n",
    "        self.target = torch.tensor(df['class'].values, dtype=torch.int64)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.vectorizer = CountVectorizer()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Fit the vectorizer on the entire text data\n",
    "        self.vectorizer.fit(self.data)\n",
    "        self.vocab_ = self.vectorizer.vocabulary_\n",
    "\n",
    "        # Convert the text data to vector representation\n",
    "        vectorized_data = torch.Tensor(self.vectorizer.transform(self.data).toarray())\n",
    "\n",
    "        # Split the dataset\n",
    "        train_size = int(0.6 * len(vectorized_data))\n",
    "        val_size = int(0.2 * len(vectorized_data))\n",
    "        test_size = len(vectorized_data) - (train_size + val_size)\n",
    "\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(\n",
    "            TweetDataset(vectorized_data, self.target),\n",
    "            [train_size, val_size, test_size]\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6670f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 8\n",
    "ds = TweetDataLoader(df, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e992222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only for inspecting data \n",
    "# ds.prepare_data()\n",
    "# ds.setup('test')\n",
    "# for data, label in ds.train_dataloader():\n",
    "#     print(data.shape,label.shape)\n",
    "#     break\n",
    "# print('Total Vocab Size : ',len(ds.vocab_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b0eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,input_shape,output_shape,weight_decay=1e-3):\n",
    "        super(NN,self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.fc1 = nn.Linear(input_shape,1000)\n",
    "        self.fc2 = nn.Linear(1000,500)\n",
    "        self.fc3 = nn.Linear(500,output_shape)\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\",num_classes=output_shape)\n",
    "        self.f1_score = torchmetrics.F1Score(task=\"multiclass\",num_classes=output_shape)\n",
    "        self.weight_decay = weight_decay\n",
    "        self.lr= 1e-3\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.log_softmax(self.fc3(x),dim=1)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss, x_hat, y = self._common_step(batch,batch_idx)\n",
    "        accuracy,f1_score = self.accuracy(x_hat,y), self.f1_score(x_hat,y)\n",
    "        \n",
    "        self.log_dict({'train_loss':loss,\n",
    "                      'train_accuracy':accuracy,\n",
    "                      'train_f1score':f1_score},prog_bar=True,on_step=False,on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, x_hat, y = self._common_step(batch,batch_idx)\n",
    "        \n",
    "        accuracy,f1_score = self.accuracy(x_hat,y), self.f1_score(x_hat,y)\n",
    "        self.log_dict({'val_loss':loss,\n",
    "                      'val_accuracy':accuracy,\n",
    "                      'val_f1score':f1_score},prog_bar=True,on_step=False,on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, x_hat, y = self._common_step(batch,batch_idx)\n",
    "        \n",
    "        accuracy,f1_score = self.accuracy(x_hat,y), self.f1_score(x_hat,y)\n",
    "        self.log_dict({'test_loss':loss,\n",
    "                      'test_accuracy':accuracy,\n",
    "                      'test_f1score':f1_score},prog_bar=True,on_step=False,on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def _common_step(self,batch,batch_index):\n",
    "        x, y = batch\n",
    "#         x = x.flatten(start_dim=1)\n",
    "        x_hat = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(x_hat,y)\n",
    "        return loss , x_hat, y\n",
    "\n",
    "    def predict_step(self,batch,batch_idx):\n",
    "        x, y = batch\n",
    "#         x = x.flatten(start_dim=1)\n",
    "        x_hat = self.forward(x)\n",
    "        pred = torch.argmax(x_hat,dim=1)\n",
    "        return pred\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(),lr=self.lr,weight_decay=self.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40248688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparametersa\n",
    "input_shape = 26439\n",
    "output_shape = 3\n",
    "batch = 512\n",
    "num_epoch = 2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = NN(input_shape,output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65321ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | fc1      | Linear             | 26.4 M\n",
      "1 | fc2      | Linear             | 500 K \n",
      "2 | fc3      | Linear             | 1.5 K \n",
      "3 | accuracy | MulticlassAccuracy | 0     \n",
      "4 | f1_score | MulticlassF1Score  | 0     \n",
      "------------------------------------------------\n",
      "26.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.9 M    Total params\n",
      "107.768   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/torchmetrics/functional/classification/accuracy.py:65: UserWarning: MPS: no support for int64 reduction ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:144.)\n",
      "  tp = tp.sum(dim=0 if multidim_average == \"global\" else 1)\n",
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ad132a53fa4284b43a2b650460f9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.736\n",
      "Epoch 0, global step 129: 'val_loss' reached 0.73609 (best 0.73609), saving model to '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=0-val_f1score=0.680.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.712\n",
      "Epoch 1, global step 258: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 387: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 516: 'val_loss' reached 0.78511 (best 0.78511), saving model to '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=3-val_f1score=0.683.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 645: 'val_loss' reached 0.88414 (best 0.88414), saving model to '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=4-val_f1score=0.680.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 774: 'val_loss' reached 0.93175 (best 0.93175), saving model to '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=5-val_f1score=0.688.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 0.712. Signaling Trainer to stop.\n",
      "Epoch 6, global step 903: 'val_loss' reached 1.01397 (best 1.01397), saving model to '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=6-val_f1score=0.668.ckpt' as top 1\n",
      "Trainer was signaled to stop but the required `min_epochs=10` or `min_steps=None` has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 6 records. Best score: 0.712. Signaling Trainer to stop.\n",
      "Epoch 7, global step 1032: 'val_loss' reached 1.06530 (best 1.06530), saving model to '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=7-val_f1score=0.682.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 7 records. Best score: 0.712. Signaling Trainer to stop.\n",
      "Epoch 8, global step 1161: 'val_loss' reached 1.07227 (best 1.07227), saving model to '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=8-val_f1score=0.681.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 8 records. Best score: 0.712. Signaling Trainer to stop.\n",
      "Epoch 9, global step 1290: 'val_loss' reached 1.08223 (best 1.08223), saving model to '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=9-val_f1score=0.683.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2297505c01844bb0a621e0650cb82a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8680858612060547     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_f1score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8680858612060547     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45739510655403137    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8680858612060547    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_f1score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8680858612060547    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45739510655403137   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.45739510655403137,\n",
       "  'val_accuracy': 0.8680858612060547,\n",
       "  'val_f1score': 0.8680858612060547}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir='./log/', name='ohe', version=0.1)\n",
    "\n",
    "profiler = pl.profilers.PyTorchProfiler(\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/',),\n",
    "    schedule=torch.profiler.schedule(skip_first=10, wait=10, warmup=1, active=2)\n",
    ")\n",
    "\n",
    "# saves top-K checkpoints based on \"val_loss\" metric\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "#     save_last=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"max\",\n",
    "    dirpath=\"checkpoints/ohe/\",\n",
    "    filename=\"{epoch}-{val_f1score:.3f}\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    accelerator='auto',\n",
    "    devices=[0],\n",
    "    min_epochs=10,\n",
    "    max_epochs=500,\n",
    "    precision='16-mixed',\n",
    "#     enable_model_summary=True,\n",
    "#     profiler=profiler,\n",
    "    callbacks=[checkpoint_callback,\n",
    "               pl.callbacks.EarlyStopping('val_loss',mode='min',patience=5,verbose=True,min_delta=0.00)],\n",
    "    enable_checkpointing  = True,\n",
    ")\n",
    "if os.path.exists(checkpoint_callback.dirpath):\n",
    "    best_checkpoint_filename = os.listdir(checkpoint_callback.dirpath)\n",
    "else: \n",
    "    best_checkpoint_filename = None\n",
    "\n",
    "if best_checkpoint_filename:\n",
    "    print('Loading model from checkpoints : ',best_checkpoint_filename[0])\n",
    "    trainer.fit(model, ds, ckpt_path=os.path.join(checkpoint_callback.dirpath, best_checkpoint_filename[0]))\n",
    "else : \n",
    "    trainer.fit(model,datamodule=ds)\n",
    "\n",
    "trainer.validate(model, ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40ce93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4017fc274d545228b3aba6455e07c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.863173246383667     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.863173246383667     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4822847545146942     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.863173246383667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_f1score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.863173246383667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4822847545146942    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test(model, ds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69ca0404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0802 09:45:25.138777 6208024576 plugin.py:429] Monitor runs begin\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.13.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=\"./log/ohe/\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
