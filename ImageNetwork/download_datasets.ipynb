{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f47e0b7-ae78-45bd-a5af-cddbbe07186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98aab744-2721-487e-9ec1-ba3b3b4aec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import AutoAugmentPolicy, AutoAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b473fcff-52bf-48dc-91c3-e9f58e5942c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TinyImageNet(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=512, num_workers=28):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.data_dir = './data'\n",
    "        self.features = None\n",
    "        self.transform = transforms.Compose([\n",
    "            # transforms.Resize((64, 64)),\n",
    "            AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        load_dataset('zh-plus/tiny-imagenet', cache_dir=self.data_dir)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            dataset = load_dataset('zh-plus/tiny-imagenet', cache_dir=self.data_dir)\n",
    "            \n",
    "            train_val_ds = dataset['train'].train_test_split(test_size=0.1)\n",
    "            self.train_dataset = train_val_ds['train'].with_transform(self.apply_transform)\n",
    "            self.val_dataset = train_val_ds['test'].with_transform(self.apply_transform)\n",
    "            self.test_dataset = dataset['valid'].with_transform(self.apply_transform)\n",
    "            self.features = self.train_dataset.features\n",
    "\n",
    "    def apply_transform(self, example):\n",
    "        example['image'] = [self.transform(img.convert('RGB')) for img in example['image']]\n",
    "        return example\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        images = torch.stack([item['image'] for item in batch])\n",
    "        labels = torch.tensor([item['label'] for item in batch])\n",
    "        return images, labels\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, pin_memory=True, collate_fn=self.collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, pin_memory=True, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, pin_memory=True, collate_fn=self.collate_fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c506514d-3589-4732-bed2-6ebd208b4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_imagenet = TinyImageNet()\n",
    "tiny_imagenet.prepare_data()\n",
    "tiny_imagenet.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "db668a91-93c3-4fcf-80a5-dd2e83430f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('label2classname.json','r') as file:\n",
    "    label2class = json.loads(file.readline())\n",
    "    label2class = {label:name for k,(label,name) in label2class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ee73bad8-1ded-4bcc-beb1-3edcbfde1b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goldfish',\n",
       " 'European_fire_salamander',\n",
       " 'bullfrog',\n",
       " 'tailed_frog',\n",
       " 'American_alligator',\n",
       " 'boa_constrictor',\n",
       " 'trilobite',\n",
       " 'scorpion',\n",
       " 'black_widow',\n",
       " 'tarantula',\n",
       " 'centipede',\n",
       " 'koala',\n",
       " 'jellyfish',\n",
       " 'brain_coral',\n",
       " 'snail',\n",
       " 'sea_slug',\n",
       " 'American_lobster',\n",
       " 'spiny_lobster',\n",
       " 'black_stork',\n",
       " 'king_penguin',\n",
       " 'albatross',\n",
       " 'dugong',\n",
       " 'Yorkshire_terrier',\n",
       " 'golden_retriever',\n",
       " 'Labrador_retriever',\n",
       " 'German_shepherd',\n",
       " 'standard_poodle',\n",
       " 'tabby',\n",
       " 'Persian_cat',\n",
       " 'Egyptian_cat',\n",
       " 'cougar',\n",
       " 'lion',\n",
       " 'brown_bear',\n",
       " 'ladybug',\n",
       " 'grasshopper',\n",
       " 'walking_stick',\n",
       " 'cockroach',\n",
       " 'mantis',\n",
       " 'dragonfly',\n",
       " 'monarch',\n",
       " 'sulphur_butterfly',\n",
       " 'sea_cucumber',\n",
       " 'guinea_pig',\n",
       " 'hog',\n",
       " 'ox',\n",
       " 'bison',\n",
       " 'bighorn',\n",
       " 'gazelle',\n",
       " 'Arabian_camel',\n",
       " 'orangutan',\n",
       " 'chimpanzee',\n",
       " 'baboon',\n",
       " 'African_elephant',\n",
       " 'lesser_panda',\n",
       " None,\n",
       " 'academic_gown',\n",
       " 'altar',\n",
       " 'backpack',\n",
       " 'bannister',\n",
       " 'barbershop',\n",
       " 'barn',\n",
       " 'barrel',\n",
       " 'basketball',\n",
       " 'bathtub',\n",
       " 'beach_wagon',\n",
       " 'beacon',\n",
       " 'beaker',\n",
       " 'beer_bottle',\n",
       " 'bikini',\n",
       " 'binoculars',\n",
       " 'birdhouse',\n",
       " 'bow_tie',\n",
       " 'brass',\n",
       " 'bucket',\n",
       " 'bullet_train',\n",
       " 'butcher_shop',\n",
       " 'candle',\n",
       " 'cannon',\n",
       " 'cardigan',\n",
       " 'cash_machine',\n",
       " 'CD_player',\n",
       " 'chest',\n",
       " 'Christmas_stocking',\n",
       " 'cliff_dwelling',\n",
       " 'computer_keyboard',\n",
       " 'confectionery',\n",
       " 'convertible',\n",
       " 'crane',\n",
       " 'dam',\n",
       " 'desk',\n",
       " 'dining_table',\n",
       " 'dumbbell',\n",
       " 'flagpole',\n",
       " None,\n",
       " 'fountain',\n",
       " 'freight_car',\n",
       " 'frying_pan',\n",
       " 'fur_coat',\n",
       " 'gasmask',\n",
       " 'go-kart',\n",
       " 'gondola',\n",
       " 'hourglass',\n",
       " 'iPod',\n",
       " 'jinrikisha',\n",
       " 'kimono',\n",
       " 'lampshade',\n",
       " 'lawn_mower',\n",
       " 'lifeboat',\n",
       " 'limousine',\n",
       " 'magnetic_compass',\n",
       " 'maypole',\n",
       " 'military_uniform',\n",
       " 'miniskirt',\n",
       " 'moving_van',\n",
       " 'neck_brace',\n",
       " 'obelisk',\n",
       " 'oboe',\n",
       " 'organ',\n",
       " 'parking_meter',\n",
       " 'pay-phone',\n",
       " 'picket_fence',\n",
       " 'pill_bottle',\n",
       " 'plunger',\n",
       " 'police_van',\n",
       " 'poncho',\n",
       " 'pop_bottle',\n",
       " \"potter's_wheel\",\n",
       " 'projectile',\n",
       " 'punching_bag',\n",
       " 'refrigerator',\n",
       " 'remote_control',\n",
       " 'rocking_chair',\n",
       " 'rugby_ball',\n",
       " 'sandal',\n",
       " 'school_bus',\n",
       " 'scoreboard',\n",
       " 'sewing_machine',\n",
       " 'snorkel',\n",
       " 'sock',\n",
       " 'sombrero',\n",
       " 'space_heater',\n",
       " 'spider_web',\n",
       " 'sports_car',\n",
       " 'steel_arch_bridge',\n",
       " 'stopwatch',\n",
       " 'sunglasses',\n",
       " 'suspension_bridge',\n",
       " 'swimming_trunks',\n",
       " 'syringe',\n",
       " 'teapot',\n",
       " 'teddy',\n",
       " 'thatch',\n",
       " 'torch',\n",
       " None,\n",
       " 'triumphal_arch',\n",
       " 'trolleybus',\n",
       " 'turnstile',\n",
       " 'umbrella',\n",
       " 'vestment',\n",
       " 'viaduct',\n",
       " 'volleyball',\n",
       " 'water_jug',\n",
       " 'water_tower',\n",
       " 'wok',\n",
       " None,\n",
       " 'comic_book',\n",
       " None,\n",
       " 'guacamole',\n",
       " 'ice_cream',\n",
       " 'ice_lolly',\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 'pretzel',\n",
       " 'mashed_potato',\n",
       " 'cauliflower',\n",
       " 'bell_pepper',\n",
       " 'lemon',\n",
       " 'banana',\n",
       " 'pomegranate',\n",
       " 'meat_loaf',\n",
       " 'pizza',\n",
       " 'potpie',\n",
       " 'espresso',\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 'alp',\n",
       " 'cliff',\n",
       " 'coral_reef',\n",
       " 'lakeside',\n",
       " 'seashore',\n",
       " 'acorn',\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[label2class.get(label) for label in tiny_imagenet.features['label'].names ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b643c73c-d698-4785-833b-b041e03369cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3, 64, 64]) tensor([115, 131, 165,  77,  63,  16, 100,  87, 111, 180,  46, 177, 182, 133,\n",
      "         99, 125,  61, 189, 143, 158, 102, 193, 132, 104,  10,  72,  60,  19,\n",
      "        126, 107, 155,  45, 160, 135, 155,  59, 117, 148, 158, 160,  88,  13,\n",
      "        177,  86,  65,  62, 162, 108,  94, 133,  23,  72,  14, 163, 190, 153,\n",
      "         66, 161,  26,  90,   4,   3, 196,  18,  73,  74, 199,  48,  48,  46,\n",
      "        145,  30, 194, 125,  30,  56,  42,  53, 146,   6,  88, 180, 142,  55,\n",
      "        114,  85, 111, 178,  30, 182,  54, 123,  33,  87,  23, 104,   2, 144,\n",
      "         44, 180,   5, 149, 160,   0, 113, 161,   9,  12, 142, 179,  72, 101,\n",
      "         33,  71,  17, 190, 113, 146,  43,  47, 131, 116,  91,  52,  14,  46,\n",
      "         41,  75, 121,  80, 179, 120,  68, 157,  29, 188, 119,  84,  92, 188,\n",
      "          0,   8,  89,  53,  27,   3, 158,  68,  35, 170,  74,  50, 159, 182,\n",
      "         56,  71,  50,  39,  64, 113,  93,  42,   9,   7,  75, 115,  31, 141,\n",
      "         80,  36, 179, 167,  53, 182,  99,  80, 179,  33, 176,  41,   7,  83,\n",
      "         29, 100,  62, 114,  94, 192, 166, 177,  92, 123,  37,  10, 147, 151,\n",
      "         15,  86,  42,  39,  84, 144,  60,  51, 171,  66, 136, 195, 116, 154,\n",
      "         85,  29, 112,  84, 145, 175,  83, 187,   6, 182,  91,  49, 192, 163,\n",
      "        161,  67, 126,  52,  37, 156,  78, 180,  85,  52,  59, 191,  34,  15,\n",
      "         91, 125, 104,   8,  64,  30, 118, 114,  71, 151, 175, 165,  34, 183,\n",
      "         66,  48, 194, 148,  84, 158,   3, 132, 171,  13,  50, 169,  88,  67,\n",
      "        185, 160, 143, 102,  66,  24,  33,  99,  80, 117, 120,  85,  82,  74,\n",
      "         32, 114, 129,  75, 131,  36, 131,  63, 122,  43, 114, 114, 190,  54,\n",
      "         69,  14, 133,   2, 123,  22,  29,   8,  64,  54,  25,  23,  57, 151,\n",
      "        180, 134, 117,  83, 173, 118,  11, 152, 140,  57,  18,   3,  27, 162,\n",
      "          6, 107, 156, 118, 144, 172,  86,  90,  93, 111, 140, 145, 176, 150,\n",
      "         95, 117,  49,  84, 128, 136,  25, 167, 188, 171,  40, 101,  60, 139,\n",
      "        189, 118,  33, 187, 163, 172,   7, 104,  64, 164,   3,  45, 185,  40,\n",
      "         62, 168, 188,  64, 118,  52, 163,  85,  18, 177, 116,  79, 112,  81,\n",
      "        100,   6,  21, 144,  75, 118, 173, 152, 104,  15,  48, 138,  27, 175,\n",
      "        118, 136,  68,  47, 107, 182,  47,  78,  45,  90, 171,  56, 132, 102,\n",
      "        174, 195,  73, 116,  83, 139, 176, 165, 137, 129,  93,  25, 136,  92,\n",
      "         13,  50, 116,  15, 143,  62,  81, 104,  29, 199, 172, 120,  32,  47,\n",
      "         80, 146,  83,  45, 157, 133, 110,  58,  57, 176, 135,   1,  22,  33,\n",
      "        179,   8, 177,  92, 170,  80,   3, 192, 128,  90,  58,   9,  99,  63,\n",
      "         62, 190, 113, 156, 110, 160,  37, 106, 156,  80, 127,  62, 119,  53,\n",
      "        186,  67,  51,  20, 179,  55,  15, 101, 137,  69,  66, 192, 127,  71,\n",
      "         27, 133, 199, 118,  92, 137,  24,  19, 174,   6, 174, 187,  69,  12,\n",
      "         29,  19,  55, 162,  91, 131,  52, 135])\n"
     ]
    }
   ],
   "source": [
    "for data,label in tiny_imagenet.train_dataloader():\n",
    "    print(data.shape,label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45af0a0a-c7b5-4304-abdb-5f204180e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
      "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n",
      "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
      "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n",
      "Downloading http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz to ./data/lfw-py/lfw-funneled.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 243346528/243346528 [06:39<00:00, 608430.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/lfw-py/lfw-funneled.tgz to ./data/lfw-py\n",
      "Downloading http://vis-www.cs.umass.edu/lfw/pairs.txt to ./data/lfw-py/pairs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 155335/155335 [00:00<00:00, 231347.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "# Corrected dataset imports with required parameters\n",
    "# coco_detection = torchvision.datasets.CocoDetection(root='./data', annFile='annotations.json')\n",
    "# celeba = torchvision.datasets.CelebA(root='./data', split='all', download=True)\n",
    "# voc_segmentation = torchvision.datasets.VOCSegmentation(root='./data', year='2012', image_set='train', download=True)\n",
    "# voc_detection = torchvision.datasets.VOCDetection(root='./data', year='2012', image_set='train', download=True)\n",
    "# coco_captions = torchvision.datasets.CocoCaptions(root='./data', annFile='annotations.json')\n",
    "ucf101 = torchvision.datasets.UCF101(root='./data', annotation_path='ucfTrainTestlist', frames_per_clip=1, step_between_clips=1, fold=1, train=True, transform=None, target_transform=None, download=True)\n",
    "moving_mnist = torchvision.datasets.MovingMNIST('./data',download=True)\n",
    "img = torchvision.datasets.FlyingChairs('./data',)\n",
    "img = torchvision.datasets.Kitti2012Stereo('./data',)\n",
    "img = torchvision.datasets.LFWPairs('./data',download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53501e-2e48-4885-8dcc-43ee2775b2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
