{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77e3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sudo Code \n",
    "# Data : \n",
    "    \n",
    "# Method : \n",
    "# Word Embedding : Weighted average TF-IDF GLoVe Model\n",
    "    \n",
    "# observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ce1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "import torchmetrics\n",
    "\n",
    "from torchtext import vocab\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c332527",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained word embedding vector\n",
    "glove = vocab.GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32833282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27480 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27480 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27480 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "df = pd.read_csv('data/Tweets.csv').dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f9b44f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b86ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textID           0\n",
      "text             0\n",
      "selected_text    0\n",
      "sentiment        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "# drop nan\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5210452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label target class\n",
    "cat_id = {'neutral': 0, \n",
    "          'negative': 2, \n",
    "          'positive': 1}\n",
    "\n",
    "df['class'] = df['sentiment'].map(cat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3594bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "def expand_contractions(text):\n",
    "    text = text.replace('`',\"'\")\n",
    "    expanded_text = contractions.fix(text)\n",
    "    return expanded_text\n",
    "\n",
    "\n",
    "def text_cleanup(text):\n",
    "    # Remove dates in the format \"YYYY-MM-DD\" or \"DD/MM/YYYY\" or \"MM/DD/YYYY\"\n",
    "    text = re.sub(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\", \"\", text)\n",
    "    text = re.sub(r\"\\b\\d{2}/\\d{2}/\\d{4}\\b\", \"\", text)\n",
    "    text = re.sub(r\"\\b\\d{2}-\\d{2}-\\d{4}\\b\", \"\", text)\n",
    "\n",
    "    # Remove times in the format \"HH:MM\" or \"HH:MM:SS\" or \"HH:MM:SS.MS\"\n",
    "    text = re.sub(r\"\\b\\d{2}:\\d{2}\\b\", \"\", text)\n",
    "    text = re.sub(r\"\\b\\d{2}:\\d{2}:\\d{2}\\b\", \"\", text)\n",
    "    text = re.sub(r\"\\b\\d{2}:\\d{2}:\\d{2}\\.\\d{2,}\\b\", \"\", text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    \n",
    "    # remove punctuations\n",
    "    translator = str.maketrans('', '', '\"#$%&\\'()*+,-./;<=>@[\\\\]^_`{|}~')\n",
    "    return text.translate(translator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfa5e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessed_df(df):\n",
    "#     tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "#     df.text = df.text.map(expand_contractions)\\\n",
    "#                         .map(text_cleanup)\\\n",
    "#                         .map(tokenizer)\n",
    "#     print(df.text.map(set).map(len).describe())\n",
    "#     return df\n",
    "# df[df.text.map(set).map(len) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e783355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n",
    "\n",
    "class TweetDataLoader(pl.LightningDataModule):\n",
    "    def __init__(self, df, batch_size, num_workers=4):\n",
    "        super(TweetDataLoader, self).__init__()\n",
    "        self.data = df['text']\n",
    "        self.target = torch.tensor(df['class'].values, dtype=torch.int64)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "        tokens = self.data.map(expand_contractions)\\\n",
    "                        .map(text_cleanup)\\\n",
    "                        .map(tokenizer)\n",
    "        tfidf = TfidfVectorizer()\n",
    "        tfidf_vec = tfidf.fit_transform(tokens.map(' '.join)).toarray()\n",
    "        features = tfidf.get_feature_names_out()\n",
    "        tfdif_pd = pd.DataFrame(tfidf_vec,columns=features)\n",
    "        word_imp = []\n",
    "        for idx,sent in enumerate(tokens):\n",
    "            word_imp.append({word : tfdif_pd[word][idx] for word in set(sent) if word in tfdif_pd.columns})\n",
    "        self.embedding = [sum([value * glove[word] for word,value in document.items()])/sum(document.values()) if sum(document.values()) else glove['unknown_word'] for document in word_imp ]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.prepare_data()\n",
    "        vectorized_data = torch.stack(self.embedding)\n",
    "        # Split the dataset\n",
    "        train_size = int(0.6 * len(vectorized_data))\n",
    "        val_size = int(0.2 * len(vectorized_data))\n",
    "        test_size = len(vectorized_data) - (train_size + val_size)\n",
    "\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(\n",
    "            TweetDataset(vectorized_data, self.target),\n",
    "            [train_size, val_size, test_size]\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6670f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 8\n",
    "ds = TweetDataLoader(df, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e992222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only for inspecting data \n",
    "# ds.prepare_data()\n",
    "# ds.setup('test')\n",
    "# for data, label in ds.train_dataloader():\n",
    "#     print(data.shape,label.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62b0eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,input_shape,output_shape):\n",
    "        super(NN,self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.fc1 = nn.Linear(input_shape,500)\n",
    "        self.fc2 = nn.Linear(500,250)\n",
    "        self.fc3 = nn.Linear(250,output_shape)\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\",num_classes=output_shape)\n",
    "        self.f1_score = torchmetrics.F1Score(task=\"multiclass\",num_classes=output_shape)\n",
    "        \n",
    "        self.lr= 1e-3\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.log_softmax(self.fc3(x),dim=1)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss, x_hat, y = self._common_step(batch,batch_idx)\n",
    "        accuracy,f1_score = self.accuracy(x_hat,y), self.f1_score(x_hat,y)\n",
    "        \n",
    "        self.log_dict({'train_loss':loss,\n",
    "                      'train_accuracy':accuracy,\n",
    "                      'train_f1score':f1_score},prog_bar=True,on_step=False,on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, x_hat, y = self._common_step(batch,batch_idx)\n",
    "        \n",
    "        accuracy,f1_score = self.accuracy(x_hat,y), self.f1_score(x_hat,y)\n",
    "        self.log_dict({'val_loss':loss,\n",
    "                      'val_accuracy':accuracy,\n",
    "                      'val_f1score':f1_score},prog_bar=True,on_step=False,on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, x_hat, y = self._common_step(batch,batch_idx)\n",
    "        \n",
    "        accuracy,f1_score = self.accuracy(x_hat,y), self.f1_score(x_hat,y)\n",
    "        self.log_dict({'test_loss':loss,\n",
    "                      'test_accuracy':accuracy,\n",
    "                      'test_f1score':f1_score},prog_bar=True,on_step=False,on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def _common_step(self,batch,batch_index):\n",
    "        x, y = batch\n",
    "#         x = x.flatten(start_dim=1)\n",
    "        x_hat = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(x_hat,y)\n",
    "        return loss , x_hat, y\n",
    "\n",
    "    def predict_step(self,batch,batch_idx):\n",
    "        x, y = batch\n",
    "#         x = x.flatten(start_dim=1)\n",
    "        x_hat = self.forward(x)\n",
    "        pred = torch.argmax(x_hat,dim=1)\n",
    "        return pred\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(),lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40248688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparametersa\n",
    "input_shape = 300\n",
    "output_shape = 3\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = NN(input_shape,output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65321ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoints :  epoch=10-val_f1score=0.602.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:615: UserWarning: Checkpoint directory /Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/glove exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Restoring states from the checkpoint path at /Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/glove/epoch=10-val_f1score=0.602.ckpt\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | fc1      | Linear             | 150 K \n",
      "1 | fc2      | Linear             | 125 K \n",
      "2 | fc3      | Linear             | 753   \n",
      "3 | accuracy | MulticlassAccuracy | 0     \n",
      "4 | f1_score | MulticlassF1Score  | 0     \n",
      "------------------------------------------------\n",
      "276 K     Trainable params\n",
      "0         Non-trainable params\n",
      "276 K     Total params\n",
      "1.106     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at /Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/glove/epoch=10-val_f1score=0.602.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e1406418164e60b47ff04c878fe907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.196 >= min_delta = 0.0. New best score: 0.611\n",
      "Epoch 11, global step 1548: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1677: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 1806: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 1935: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 2064: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 2193: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 2322: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 7 records. Best score: 0.611. Signaling Trainer to stop.\n",
      "Epoch 18, global step 2451: 'val_loss' was not in top 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir='./log/', name='glove', version=0.1)\n",
    "\n",
    "profiler = pl.profilers.PyTorchProfiler(\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/',),\n",
    "    schedule=torch.profiler.schedule(skip_first=10, wait=10, warmup=1, active=2)\n",
    ")\n",
    "\n",
    "# saves top-K checkpoints based on \"val_loss\" metric\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "#     save_last=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"max\",\n",
    "    dirpath=\"checkpoints/glove/\",\n",
    "    filename=\"{epoch}-{val_f1score:.3f}\",\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    accelerator='auto',\n",
    "    devices=[0],\n",
    "    min_epochs=10,\n",
    "    max_epochs=500,\n",
    "    precision='16-mixed',\n",
    "#     enable_model_summary=True,\n",
    "#     profiler=profiler,\n",
    "    callbacks=[checkpoint_callback,\n",
    "               pl.callbacks.EarlyStopping('val_loss',mode='min',patience=20,verbose=True,min_delta=0.00)],\n",
    "    enable_checkpointing  = True,\n",
    ")\n",
    "\n",
    "if os.path.exists(checkpoint_callback.dirpath):\n",
    "    best_checkpoint_filename = os.listdir(checkpoint_callback.dirpath)\n",
    "else: \n",
    "    best_checkpoint_filename = None\n",
    "\n",
    "if best_checkpoint_filename:\n",
    "    print('Loading model from checkpoints : ',best_checkpoint_filename[0])\n",
    "    trainer.fit(model, ds, ckpt_path=os.path.join(checkpoint_callback.dirpath, best_checkpoint_filename[0]))\n",
    "else : \n",
    "    trainer.fit(model,datamodule=ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(model, datamodule = ds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40ce93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81faf94aeefa4deaa658473928cc1fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavjha/anaconda3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.756732165813446     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.756732165813446     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6797810792922974     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.756732165813446    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_f1score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.756732165813446    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6797810792922974    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=ds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ca0404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"<string>\", line 1, in <module>\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/pranavjha/anaconda3/bin/tensorboard\", line 8, in <module>\r\n",
      "    sys.exit(run_main())\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/main.py\", line 46, in run_main\r\n",
      "    exitcode = _main(fd, parent_sentinel)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 125, in _main\r\n",
      "    prepare(preparation_data)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 236, in prepare\r\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 287, in _fixup_main_from_path\r\n",
      "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/absl/app.py\", line 308, in run\r\n",
      "    main_content = runpy.run_path(main_path,\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/runpy.py\", line 289, in run_path\r\n",
      "    return _run_module_code(code, init_globals, run_name,\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/runpy.py\", line 96, in _run_module_code\r\n",
      "    _run_main(main, args)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/absl/app.py\", line 254, in _run_main\r\n",
      "    _run_code(code, mod_globals, init_globals,\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/runpy.py\", line 86, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/Users/pranavjha/anaconda3/bin/tensorboard\", line 5, in <module>\r\n",
      "    sys.exit(main(argv))\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/program.py\", line 276, in main\r\n",
      "    from tensorboard.main import run_main\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/main.py\", line 27, in <module>\r\n",
      "    from tensorboard import default\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/default.py\", line 37, in <module>\r\n",
      "    from tensorboard.plugins.graph import graphs_plugin\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/plugins/graph/graphs_plugin.py\", line 30, in <module>\r\n",
      "    return runner(self.flags) or 0\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/program.py\", line 292, in _run_serve_subcommand\r\n",
      "    server = self._make_server()\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/program.py\", line 467, in _make_server\r\n",
      "    from tensorboard.plugins.graph import keras_util\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/plugins/graph/keras_util.py\", line 45, in <module>\r\n",
      "    from tensorboard.compat.tensorflow_stub import dtypes\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/__init__.py\", line 18, in <module>\r\n",
      "    app = application.TensorBoardWSGIApp(\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 123, in TensorBoardWSGIApp\r\n",
      "    from tensorboard.compat.proto.event_pb2 import *  # noqa\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/compat/proto/event_pb2.py\", line 106, in <module>\r\n",
      "    plugin = loader.load(context)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/tensorboard/plugins/base_plugin.py\", line 362, in load\r\n",
      "    return self.plugin_class(context)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/torch_tb_profiler/plugin.py\", line 60, in __init__\r\n",
      "    WorkerHeartbeatResponse = _reflection.GeneratedProtocolMessageType('WorkerHeartbeatResponse', (_message.Message,), {\r\n",
      "    self._cache = io.Cache(self._temp_dir)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/google/protobuf/internal/python_message.py\", line 193, in __init__\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/torch_tb_profiler/io/cache.py\", line 17, in __init__\r\n",
      "    self._manager = mp.Manager()\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/multiprocessing/context.py\", line 57, in Manager\r\n",
      "    _AttachFieldHelpers(cls, field)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/google/protobuf/internal/python_message.py\", line 309, in _AttachFieldHelpers\r\n",
      "    m.start()\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/multiprocessing/managers.py\", line 566, in start\r\n",
      "    field_encoder = type_checkers.TYPE_TO_ENCODER[field_descriptor.type](\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/google/protobuf/internal/encoder.py\", line 462, in SpecificEncoder\r\n",
      "    tag_bytes = TagBytes(field_number, wire_type)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/google/protobuf/internal/encoder.py\", line 423, in TagBytes\r\n",
      "    return bytes(_VarintBytes(wire_format.PackTag(field_number, wire_type)))\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/site-packages/google/protobuf/internal/wire_format.py\", line 88, in PackTag\r\n",
      "    self._address = reader.recv()\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/multiprocessing/connection.py\", line 250, in recv\r\n",
      "    if not 0 <= wire_type <= _WIRETYPE_MAX:\r\n",
      "KeyboardInterrupt\r\n",
      "    buf = self._recv_bytes()\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\r\n",
      "    buf = self._recv(4)\r\n",
      "  File \"/Users/pranavjha/anaconda3/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\r\n",
      "    chunk = read(handle, remaining)\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=\"./log/glove/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9674cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 9,\n",
       " 'global_step': 1290,\n",
       " 'pytorch-lightning_version': '2.0.3',\n",
       " 'state_dict': OrderedDict([('fc1.weight',\n",
       "               tensor([[-1.5610e-02,  2.5858e-03, -5.4323e-32,  ..., -1.9498e-29,\n",
       "                         4.2148e-29,  1.9831e-04],\n",
       "                       [-1.5386e-02, -8.3821e-03, -2.2433e-03,  ..., -4.6120e-33,\n",
       "                         5.3142e-04, -4.2521e-03],\n",
       "                       [ 5.6590e-04,  7.0596e-06, -5.7698e-18,  ...,  5.5298e-23,\n",
       "                        -3.3125e-06,  1.4006e-04],\n",
       "                       ...,\n",
       "                       [ 1.5866e-04,  2.4055e-10,  3.3845e-23,  ..., -1.9895e-23,\n",
       "                        -3.0473e-05, -7.0479e-05],\n",
       "                       [-3.4253e-04,  8.4176e-06,  1.6359e-03,  ...,  3.6487e-16,\n",
       "                        -1.3511e-14,  6.4651e-04],\n",
       "                       [-3.5185e-04, -2.2445e-03, -2.8573e-26,  ..., -1.0210e-31,\n",
       "                         4.5169e-24,  7.6417e-07]], device='mps:0')),\n",
       "              ('fc1.bias',\n",
       "               tensor([ 3.1527e-03,  2.6895e-02, -2.4286e-03,  1.6973e-03,  2.6386e-02,\n",
       "                        4.9205e-03, -1.2336e-03,  1.6973e-02,  2.5711e-04,  2.0019e-03,\n",
       "                       -3.9033e-04, -5.4530e-03, -5.6413e-03,  3.6348e-02, -3.4299e-03,\n",
       "                        3.6040e-02, -1.4710e-03, -1.9439e-03, -4.1514e-03, -1.3049e-02,\n",
       "                       -9.9200e-04, -1.3510e-02,  1.3926e-03, -4.2258e-03,  3.7635e-02,\n",
       "                        4.0010e-03, -2.4277e-03, -3.0855e-03, -1.4728e-03, -1.3136e-02,\n",
       "                       -4.2024e-03, -1.5780e-02, -3.8756e-03,  2.9235e-02, -2.0007e-03,\n",
       "                       -1.4897e-02,  1.7937e-02,  1.0580e-02,  9.2145e-03, -1.6603e-03,\n",
       "                       -1.8830e-02, -5.2646e-03,  7.4511e-04, -1.1484e-04, -5.0499e-04,\n",
       "                       -1.0087e-02, -6.1544e-03, -5.5209e-03, -2.8343e-04,  2.1425e-02,\n",
       "                       -8.4162e-03, -3.8009e-03,  5.8741e-03, -2.2578e-03,  3.3713e-02,\n",
       "                       -3.1804e-03,  3.0815e-02,  7.4647e-04,  2.1801e-03, -2.4102e-03,\n",
       "                       -2.8344e-03,  4.2677e-02, -9.3404e-03,  3.5181e-03, -3.1834e-02,\n",
       "                        7.0790e-02,  5.7296e-03, -1.0714e-04,  6.9939e-03,  1.3694e-02,\n",
       "                        9.7722e-03,  4.7336e-02,  2.0674e-03,  3.0069e-03,  1.0353e-02,\n",
       "                        1.0418e-02,  2.0164e-02,  1.2360e-03,  1.7277e-02, -5.2712e-04,\n",
       "                        5.4907e-04,  3.4854e-03,  1.1726e-04,  2.2587e-03, -7.9723e-04,\n",
       "                       -1.2226e-03,  2.7365e-02,  8.3133e-03,  1.4150e-02, -1.0322e-02,\n",
       "                       -5.7502e-03,  4.2738e-03, -6.9240e-03, -2.1005e-02,  1.8355e-03,\n",
       "                        3.5525e-02, -3.2967e-03,  4.1637e-03, -9.9468e-03,  2.9081e-03,\n",
       "                       -1.1112e-02,  1.1441e-02,  3.4942e-03,  4.1816e-04, -2.4652e-03,\n",
       "                       -1.5726e-03,  2.9298e-02,  1.6339e-02,  1.8354e-03, -1.4945e-04,\n",
       "                       -2.2198e-03,  6.6219e-04,  5.0329e-03, -1.8818e-04, -7.5574e-03,\n",
       "                       -1.1427e-02,  4.3701e-02, -1.7416e-03,  1.2422e-03, -3.1572e-03,\n",
       "                        7.4873e-04,  1.3068e-02, -4.7916e-03, -9.1189e-03,  5.3168e-03,\n",
       "                       -5.7333e-04,  2.8744e-02, -4.6015e-03,  2.3216e-03, -2.1762e-03,\n",
       "                        1.1539e-02,  1.3723e-04, -6.6884e-03,  1.7236e-03,  5.2292e-04,\n",
       "                        2.2337e-03,  4.3477e-03,  1.7044e-02,  1.2340e-02, -7.2215e-04,\n",
       "                        2.1061e-02, -7.4283e-03,  1.6953e-02, -2.8075e-03,  2.2847e-03,\n",
       "                       -7.5662e-04,  2.4579e-02, -1.8541e-06, -4.0032e-07, -5.3019e-03,\n",
       "                       -1.1471e-02,  1.8205e-02, -7.1929e-03, -2.6190e-04,  3.4680e-02,\n",
       "                        1.9278e-03,  6.4099e-04,  1.8509e-02, -9.6965e-03,  2.5187e-02,\n",
       "                       -3.9953e-05, -3.0525e-03,  6.9851e-04, -7.7572e-03,  6.7714e-03,\n",
       "                       -3.1542e-04, -2.7873e-03,  8.5734e-03, -6.6992e-03, -6.1409e-03,\n",
       "                        5.8358e-04, -1.4978e-03, -5.2299e-03,  2.2437e-03, -7.8479e-03,\n",
       "                        2.5158e-02, -5.2806e-04, -2.5987e-03, -9.6567e-03, -1.1568e-03,\n",
       "                        4.2382e-04, -6.0822e-03, -9.6721e-04, -4.2199e-03, -1.7246e-03,\n",
       "                        3.2813e-03, -1.0089e-02,  5.9765e-04,  5.1507e-03, -1.8804e-03,\n",
       "                       -6.7032e-04, -4.6246e-03,  8.2955e-03,  3.5353e-02, -2.1681e-04,\n",
       "                       -1.4297e-03, -4.4477e-03,  3.4356e-03, -1.8559e-04, -1.6740e-03,\n",
       "                        1.0815e-02,  1.8203e-02,  7.8277e-03,  1.5774e-03, -1.2799e-03,\n",
       "                        1.5162e-02, -1.0391e-02, -3.1807e-02, -5.7335e-04, -6.1761e-03,\n",
       "                        5.0263e-05, -1.1185e-02,  1.9433e-02, -4.0860e-03, -1.9233e-03,\n",
       "                        1.4362e-02, -7.1254e-03, -2.8631e-03,  3.0266e-04, -1.3928e-02,\n",
       "                       -9.7242e-03,  2.4079e-02,  1.7863e-02,  6.6348e-03,  9.8008e-03,\n",
       "                       -2.4514e-04, -4.0780e-07,  6.1094e-03,  1.2558e-02, -2.9441e-03,\n",
       "                        1.0759e-03, -3.2472e-03,  1.1029e-02, -2.2977e-03,  2.4906e-02,\n",
       "                        3.1353e-02, -6.5931e-03, -1.7689e-04, -1.1931e-02,  3.1548e-03,\n",
       "                       -1.7090e-02,  1.9258e-02, -2.6564e-02,  3.5973e-02,  8.0155e-03,\n",
       "                        5.7290e-02, -7.6304e-03,  4.5738e-03,  6.2815e-04,  1.2454e-02,\n",
       "                        2.5084e-02, -3.0635e-03,  1.6688e-02,  5.5673e-02, -1.8280e-02,\n",
       "                       -8.8716e-05, -5.0720e-04, -2.9195e-04,  1.0752e-02,  1.5918e-03,\n",
       "                        2.5219e-03, -1.3423e-04,  7.4671e-03,  1.1203e-03, -1.6150e-03,\n",
       "                        1.8931e-03,  2.5347e-03, -2.2055e-03, -1.2952e-02,  7.9072e-03,\n",
       "                        3.7735e-02, -7.7142e-03,  1.8649e-02,  2.0050e-02,  2.1831e-02,\n",
       "                       -1.5745e-03, -7.6910e-04,  8.5913e-03, -5.1992e-03, -5.7871e-04,\n",
       "                       -7.3442e-04, -4.3154e-03,  1.5863e-03, -2.1630e-02,  2.5663e-03,\n",
       "                       -9.2821e-03, -6.0226e-04,  8.9302e-03, -2.4353e-02, -8.4821e-03,\n",
       "                       -2.5050e-03, -8.3623e-04,  3.0637e-02, -1.1857e-04, -5.6373e-02,\n",
       "                        3.7583e-02,  3.7317e-02,  4.9756e-02, -4.7669e-03,  1.7978e-02,\n",
       "                       -1.5444e-06,  3.1562e-03, -1.1337e-02,  8.0897e-03,  1.4628e-02,\n",
       "                        2.1174e-02,  3.2405e-02,  6.8466e-04, -2.4140e-02,  6.9757e-03,\n",
       "                       -2.5790e-03, -4.4650e-03,  4.4871e-02, -7.2725e-03, -6.0117e-03,\n",
       "                        1.1531e-02, -8.5982e-04,  5.1865e-02, -6.0604e-03,  1.1729e-04,\n",
       "                        1.3543e-03, -4.5006e-03,  1.3248e-03,  1.6633e-02,  1.6226e-02,\n",
       "                       -5.4726e-03,  6.6401e-03, -5.1320e-04,  1.3496e-03, -1.5542e-03,\n",
       "                       -3.4018e-03,  3.5847e-03,  1.6026e-02, -2.9227e-03, -3.8318e-03,\n",
       "                        1.2225e-02,  2.0822e-02,  3.3890e-04, -2.0776e-03,  4.3545e-03,\n",
       "                       -8.6187e-05, -6.6968e-03,  1.4193e-05, -3.3377e-02,  1.2603e-03,\n",
       "                        1.1868e-02, -3.4902e-02,  3.8482e-03,  1.6483e-03,  3.6906e-04,\n",
       "                       -1.2293e-02,  7.2788e-03, -2.8681e-03, -8.0927e-04, -9.3951e-04,\n",
       "                       -2.4004e-03, -3.1778e-03, -3.8825e-03,  6.5016e-03, -7.1562e-04,\n",
       "                        2.6737e-03,  1.8626e-03, -7.2784e-04, -1.7460e-03, -9.0310e-03,\n",
       "                       -1.8055e-03,  4.6427e-02,  3.6205e-02, -1.2942e-04,  1.7647e-02,\n",
       "                       -7.1322e-04,  1.2780e-03, -1.4449e-02,  9.5608e-03,  1.3115e-02,\n",
       "                        1.7240e-02, -1.1432e-03, -4.2213e-03,  7.7751e-04, -4.3125e-03,\n",
       "                        7.1689e-02,  3.7528e-02, -3.2653e-03,  1.7541e-04,  3.8824e-03,\n",
       "                        8.2136e-04, -2.5220e-08, -3.0269e-03,  5.4959e-03, -2.8556e-04,\n",
       "                        5.5390e-03,  2.5459e-02,  3.1966e-02,  9.3090e-03,  2.7071e-02,\n",
       "                        1.6577e-03, -3.0666e-03,  1.3737e-02, -5.7256e-04, -9.1327e-03,\n",
       "                        2.1314e-02, -7.4633e-03, -3.3508e-03,  3.8524e-02,  5.2281e-02,\n",
       "                       -2.8428e-02, -2.8560e-03,  5.6068e-02, -2.0135e-02, -5.7215e-03,\n",
       "                        1.8258e-02, -4.2049e-03,  3.2083e-03, -5.2631e-03, -2.6262e-03,\n",
       "                        4.0239e-03,  9.1416e-03, -8.1104e-03,  3.2788e-03,  1.1686e-02,\n",
       "                        2.0930e-03, -3.3820e-03, -1.9488e-03, -2.6827e-02,  3.2718e-03,\n",
       "                       -9.8594e-04,  1.6976e-02,  2.4826e-02, -4.0704e-03,  3.8630e-02,\n",
       "                       -3.0527e-03, -1.6175e-02, -4.6889e-03,  2.2304e-02,  3.0312e-02,\n",
       "                        1.4454e-02,  1.1172e-02, -3.9933e-02, -1.0116e-02,  1.3074e-02,\n",
       "                        2.1997e-02,  4.6098e-03,  3.7805e-03,  1.3699e-03, -5.6683e-05,\n",
       "                        4.8838e-03, -4.1651e-05, -9.7601e-03,  6.0034e-03,  3.6352e-02,\n",
       "                        2.0473e-02, -6.2157e-03,  1.2688e-02,  1.8726e-02,  5.9714e-03,\n",
       "                       -7.1721e-03,  1.4318e-03,  4.7587e-04, -1.7155e-02, -2.1137e-03,\n",
       "                        7.5063e-03,  8.7140e-04, -2.6156e-02, -8.0326e-04,  9.8584e-03,\n",
       "                       -7.7773e-03,  8.7402e-03, -4.9736e-03, -2.7785e-03,  2.4999e-02,\n",
       "                       -1.8607e-03, -3.1046e-03,  5.8294e-03, -1.1170e-02,  2.0909e-03,\n",
       "                        2.9830e-03,  3.6698e-02,  1.7140e-03, -5.9991e-03,  4.4132e-03,\n",
       "                        5.3877e-03, -9.2595e-06, -2.6480e-02,  7.6547e-04, -1.4726e-02,\n",
       "                        4.7708e-03, -3.5961e-03, -3.4187e-03, -1.9367e-02, -1.7430e-03,\n",
       "                       -2.6368e-03, -8.1305e-04, -9.8646e-03, -7.4047e-03, -9.2911e-03,\n",
       "                       -1.0334e-02, -8.2260e-03,  1.5730e-02, -2.4521e-04, -1.8208e-03,\n",
       "                        3.9408e-02,  3.0749e-03,  4.9345e-03, -1.0652e-02,  2.0323e-03,\n",
       "                       -6.5076e-03, -2.8955e-03,  1.5525e-03,  6.8638e-02, -1.6737e-02,\n",
       "                        4.0512e-03, -2.3618e-02, -3.0851e-04,  2.2761e-03,  1.3418e-02,\n",
       "                       -6.2486e-03, -1.0026e-02,  2.5647e-05, -1.4945e-04,  3.1002e-03,\n",
       "                        3.2082e-02,  3.1167e-02, -1.1058e-03,  3.5703e-03,  2.3207e-02,\n",
       "                        1.5684e-03, -5.2633e-03,  1.4654e-03, -8.0080e-03,  2.3949e-02,\n",
       "                        1.0505e-02,  2.5624e-02, -9.3912e-05, -9.1751e-03, -2.3760e-03,\n",
       "                        1.2463e-02, -2.2814e-03,  7.0943e-03, -2.4518e-13,  2.7142e-03,\n",
       "                       -5.1849e-03,  4.8747e-03, -2.7836e-04, -2.7753e-03, -4.8486e-03,\n",
       "                        2.0565e-03, -6.2123e-03,  1.8118e-03, -3.6955e-03, -3.2568e-03,\n",
       "                        1.5232e-03,  3.8657e-03,  4.1427e-05,  1.9057e-02,  3.6230e-04,\n",
       "                       -6.2406e-09, -3.2459e-02, -8.0584e-04,  2.4198e-02,  1.5703e-02,\n",
       "                       -2.8837e-03,  3.1119e-02,  4.1680e-03,  6.7755e-02, -1.8659e-02,\n",
       "                       -6.3130e-02,  4.2765e-03,  1.0851e-02,  1.4896e-02, -1.2421e-03,\n",
       "                       -1.6761e-03, -2.1335e-03, -1.5684e-02,  1.1694e-02, -1.4206e-02,\n",
       "                       -1.7101e-02, -3.3721e-03,  2.0658e-03,  3.0270e-03, -2.5060e-03,\n",
       "                        7.1966e-03,  1.2627e-02,  1.4273e-02, -2.5667e-03, -3.0863e-02,\n",
       "                       -6.1069e-05, -6.8902e-04,  7.5979e-05, -1.0071e-03, -3.3150e-03,\n",
       "                        1.1370e-03,  5.2620e-03,  1.0805e-03, -1.3018e-02, -1.1139e-03,\n",
       "                       -6.3388e-03, -3.8049e-03,  1.6812e-02,  5.7578e-03,  1.3222e-02,\n",
       "                        1.2181e-02, -6.1711e-03, -5.6403e-03,  1.2867e-02, -2.4339e-02,\n",
       "                        1.3766e-02, -1.1190e-04,  4.5156e-02,  1.2609e-02, -2.1632e-03,\n",
       "                       -7.6061e-03,  5.0570e-03,  1.9575e-02,  4.1089e-04, -1.6319e-03,\n",
       "                        3.5880e-04,  4.1572e-03, -9.0411e-03, -2.3596e-02,  1.1623e-03,\n",
       "                       -7.1952e-03,  1.4844e-02,  2.1912e-02, -3.8808e-04, -2.6008e-03,\n",
       "                       -3.1722e-03, -1.1245e-02, -3.2195e-03, -6.0168e-04, -3.0151e-03,\n",
       "                       -3.6219e-03,  1.8630e-02, -1.1717e-03, -7.7987e-03,  2.3965e-02,\n",
       "                       -1.2135e-03, -4.0225e-03, -7.4607e-03, -7.6015e-03, -4.3804e-03,\n",
       "                        2.2247e-03,  2.6148e-02,  1.2974e-02,  7.4316e-04, -9.8694e-03,\n",
       "                       -7.6199e-03, -4.4706e-03, -5.6119e-02,  1.1934e-02,  2.8383e-02,\n",
       "                        4.0445e-03,  1.5033e-02,  6.0266e-03, -6.7298e-04,  4.1555e-02,\n",
       "                        3.7926e-02, -7.6308e-08, -3.3915e-03, -5.7696e-04, -5.6469e-03,\n",
       "                        1.7076e-02,  8.2029e-04,  2.9513e-03,  3.8474e-02,  2.6664e-02,\n",
       "                        8.5698e-03, -3.3571e-06,  1.2112e-03,  2.5609e-02,  5.1866e-03,\n",
       "                       -1.0266e-02, -1.8789e-03, -1.0154e-02,  2.3441e-02, -5.5911e-04,\n",
       "                       -6.4186e-03,  1.2314e-03, -2.2481e-03, -4.4542e-03, -5.9756e-04,\n",
       "                        3.5455e-02, -7.0794e-03,  3.8743e-02, -1.5975e-03, -6.4683e-03,\n",
       "                        3.1582e-02, -1.7522e-03,  1.2514e-02, -5.4811e-05,  1.5480e-02,\n",
       "                       -1.7014e-02, -2.8589e-03, -1.2163e-03,  2.0874e-02, -4.5572e-03,\n",
       "                       -6.7196e-03, -1.5369e-03,  2.8729e-03,  7.0976e-04,  4.2290e-02,\n",
       "                       -1.1740e-03, -5.8604e-03,  1.9818e-03, -5.2015e-04,  5.8490e-04,\n",
       "                        1.1863e-03,  6.9273e-04, -3.4536e-03, -1.3538e-03, -2.5649e-02,\n",
       "                        6.5679e-03, -3.6380e-03,  3.8227e-03, -6.4776e-04,  1.3898e-03,\n",
       "                       -8.6867e-05,  1.9769e-03, -1.7729e-03, -3.1167e-04, -5.1037e-03,\n",
       "                        1.1838e-02,  8.7553e-03, -1.4207e-04,  6.5914e-02, -2.1341e-03,\n",
       "                       -1.5338e-02, -1.9615e-03, -3.9775e-04, -5.6599e-03, -1.5491e-04,\n",
       "                       -3.6249e-02,  8.4040e-03,  5.9973e-02, -8.2391e-03,  1.1349e-03,\n",
       "                        1.4970e-02, -1.3406e-02,  9.2812e-03,  2.0576e-02,  2.3075e-04,\n",
       "                       -6.6576e-04,  3.4979e-02, -6.3461e-03,  2.5839e-02, -1.1647e-03,\n",
       "                        2.7756e-04,  2.2379e-02, -1.1312e-02,  4.2767e-02, -5.3262e-03,\n",
       "                        5.0902e-02, -7.0677e-04,  1.8265e-02, -8.4144e-03,  1.9170e-02,\n",
       "                        8.7043e-03, -5.9721e-02,  7.0385e-03,  8.8087e-04,  6.1465e-03,\n",
       "                       -1.0275e-02, -8.0565e-06,  1.5030e-02, -1.2995e-03, -3.1261e-03,\n",
       "                       -7.1499e-03, -3.2460e-03, -1.0260e-02,  1.5702e-03,  3.2337e-02,\n",
       "                       -4.1744e-03,  3.5003e-02, -1.7361e-03,  3.5818e-03, -1.6172e-03,\n",
       "                       -3.1855e-03,  2.4896e-03,  6.4036e-03,  1.6237e-02,  1.0744e-03,\n",
       "                       -2.4089e-03, -1.1811e-02,  1.3396e-03,  1.0091e-03, -3.6792e-03,\n",
       "                       -4.3979e-03, -2.7361e-03,  1.1846e-03, -5.5311e-03, -2.2143e-03,\n",
       "                        4.7081e-03, -1.1770e-02,  1.5330e-02, -5.9613e-04, -2.9704e-02,\n",
       "                       -5.8861e-03,  3.5717e-03, -1.5357e-02,  2.7821e-03,  1.6634e-02,\n",
       "                       -3.6309e-03,  3.3858e-02, -1.7923e-02, -5.0657e-04,  2.0151e-02,\n",
       "                        3.2526e-02,  3.9089e-02,  5.3992e-04, -4.5104e-03, -5.7299e-03,\n",
       "                       -1.1360e-04,  5.8510e-04,  2.8204e-03, -1.6293e-03,  4.0280e-03,\n",
       "                       -9.1965e-03,  6.6387e-04, -3.0155e-02, -7.5949e-06,  3.6998e-03,\n",
       "                       -2.0318e-03,  2.1581e-02,  1.0052e-02, -2.0215e-03,  3.5425e-02,\n",
       "                       -5.8818e-03,  5.5081e-02,  3.9582e-04, -1.5651e-03,  2.5129e-04,\n",
       "                       -5.5081e-03, -2.0282e-10, -9.1753e-04, -4.7589e-03, -1.3852e-03,\n",
       "                       -2.1370e-02, -4.2807e-04,  2.8009e-02, -2.3269e-03, -6.4258e-03,\n",
       "                        1.3343e-03,  1.6907e-02, -1.1889e-02, -9.4046e-03, -2.9929e-03,\n",
       "                       -1.4374e-03,  5.0373e-03,  3.5340e-03, -5.7395e-05,  1.7083e-03,\n",
       "                        2.1120e-03, -4.6071e-03,  6.2563e-02,  2.0581e-03, -9.3957e-03,\n",
       "                       -2.8269e-03,  6.9234e-05, -1.5472e-03, -1.9011e-04, -5.5881e-03,\n",
       "                       -2.5047e-02, -2.5407e-05,  5.3212e-03, -3.1028e-03,  3.1147e-02,\n",
       "                        4.7868e-02,  6.7806e-04, -3.1778e-03,  1.7476e-02, -7.3408e-04,\n",
       "                       -2.4254e-03,  1.5416e-03,  1.9942e-03,  3.1062e-04,  2.2169e-02,\n",
       "                       -1.0038e-03,  2.4979e-02, -2.9089e-03, -8.9109e-03,  8.8566e-04,\n",
       "                       -8.2330e-04,  4.1757e-02, -8.2414e-04,  2.6421e-04, -1.3923e-02,\n",
       "                       -1.6215e-03, -7.6625e-03,  8.8815e-03,  7.2878e-03,  5.9669e-03,\n",
       "                        2.3625e-02, -1.5456e-03,  1.6961e-02, -1.0432e-04, -1.3498e-02,\n",
       "                        1.0507e-03,  3.9250e-02,  1.1027e-04,  1.0152e-03,  7.3369e-04,\n",
       "                       -3.5908e-04, -5.1427e-03, -5.5631e-03,  4.5131e-03, -1.0835e-03,\n",
       "                        2.2107e-02, -6.8878e-03, -5.1936e-03, -2.1205e-02,  3.7474e-03,\n",
       "                       -4.3102e-03, -5.1076e-03,  1.3065e-03,  8.6266e-03, -2.8536e-02,\n",
       "                       -2.4931e-03, -3.1991e-03,  1.6985e-02, -3.3134e-04,  2.1821e-02,\n",
       "                        2.5850e-03, -2.7932e-03,  3.4186e-02, -3.4687e-02, -5.9210e-03,\n",
       "                       -1.5163e-02, -1.0271e-03, -1.2281e-04,  6.3120e-04,  1.1352e-02,\n",
       "                       -4.1092e-03, -3.1718e-03,  8.7858e-04, -9.7780e-04, -5.1803e-03,\n",
       "                        1.7389e-02, -3.4637e-04, -7.2242e-04, -4.2745e-05, -1.3315e-03,\n",
       "                       -1.2606e-02, -2.1249e-03,  3.3787e-03,  2.4795e-02,  2.2404e-02,\n",
       "                        1.6174e-02,  1.3023e-03, -7.0155e-03, -4.6216e-05, -1.9896e-02,\n",
       "                       -1.1112e-03,  1.4207e-02,  2.2829e-02,  7.5997e-04, -5.2800e-04,\n",
       "                        3.9984e-02, -6.9959e-03, -2.6547e-02, -6.4551e-04,  4.1252e-03,\n",
       "                       -1.8171e-03,  1.0082e-03, -2.0220e-03,  1.7136e-03, -5.1567e-03,\n",
       "                        6.4384e-03, -1.5363e-03, -1.2587e-03,  1.2413e-03, -6.5286e-04,\n",
       "                        1.7826e-02,  2.0764e-02, -3.9642e-05, -1.7618e-02, -2.3804e-05,\n",
       "                        1.0028e-02, -2.1368e-02,  2.8250e-04, -5.6009e-03, -1.9302e-03,\n",
       "                       -3.7642e-02,  2.3264e-02, -2.1272e-03, -2.9809e-02, -2.2017e-02,\n",
       "                       -7.9839e-04,  2.4816e-02, -9.3495e-03, -1.1844e-03, -6.1087e-05,\n",
       "                        3.6381e-03,  2.3203e-03, -1.2912e-02,  4.1999e-02,  2.1718e-03,\n",
       "                        3.2243e-02,  3.4341e-02,  1.3571e-03,  8.8876e-03,  3.4878e-03],\n",
       "                      device='mps:0')),\n",
       "              ('fc2.weight',\n",
       "               tensor([[ 7.7544e-02,  8.8848e-03,  4.1409e-03,  ...,  2.3676e-03,\n",
       "                         9.3346e-03,  5.3023e-03],\n",
       "                       [-2.4990e-13, -6.1743e-13,  3.0765e-12,  ...,  1.0276e-12,\n",
       "                         4.6493e-13,  1.7712e-13],\n",
       "                       [ 3.2833e-02, -1.2310e-02, -1.8389e-03,  ...,  1.0387e-03,\n",
       "                         4.9118e-03,  7.1251e-04],\n",
       "                       ...,\n",
       "                       [-3.4207e-02,  2.9880e-02,  4.7063e-03,  ..., -7.6228e-04,\n",
       "                        -4.9324e-03,  2.1533e-04],\n",
       "                       [-5.9820e-02,  4.3892e-02,  4.0036e-03,  ..., -1.4022e-03,\n",
       "                        -8.0994e-03,  7.0971e-04],\n",
       "                       [-2.1790e-03, -3.7962e-02, -1.9408e-03,  ...,  4.1389e-04,\n",
       "                         2.2542e-03, -3.8540e-03]], device='mps:0')),\n",
       "              ('fc2.bias',\n",
       "               tensor([ 2.1986e-02, -4.5438e-05,  4.1475e-02,  7.7249e-02, -1.0132e-05,\n",
       "                        6.3404e-02,  6.9834e-02, -2.5350e-06, -6.1492e-09,  4.5667e-02,\n",
       "                        5.6588e-02,  4.1427e-02,  2.0500e-02,  4.0708e-02,  5.3302e-02,\n",
       "                        4.3706e-02,  9.6431e-02,  7.2820e-02,  4.6408e-02,  2.5298e-02,\n",
       "                       -1.9405e-12, -1.0965e-11,  6.8093e-02,  4.3641e-02,  4.2035e-02,\n",
       "                       -6.6854e-05,  5.6436e-02,  3.3972e-10,  8.4045e-02, -3.2560e-12,\n",
       "                        6.5601e-02,  7.3641e-02,  6.6772e-02, -1.4277e-11,  4.6802e-02,\n",
       "                       -9.8702e-09, -8.1566e-10,  6.5101e-02,  4.0192e-02, -1.9296e-08,\n",
       "                        2.0875e-02, -5.9046e-08, -1.0714e-05,  4.0334e-02, -1.4339e-10,\n",
       "                        5.5478e-02, -1.1378e-11,  6.1822e-02,  2.8116e-02,  6.1497e-02,\n",
       "                        7.7795e-02, -2.6557e-16,  4.5849e-02,  8.1349e-02,  6.7596e-02,\n",
       "                       -8.6297e-06, -4.1858e-18,  5.6162e-02, -7.9223e-05,  2.3160e-02,\n",
       "                        4.2015e-02,  2.2052e-02,  7.0129e-02,  5.3604e-02,  3.1949e-02,\n",
       "                        7.4448e-02,  7.9259e-02, -5.7659e-14,  6.0379e-02,  6.4607e-02,\n",
       "                       -4.1772e-14, -5.4541e-04,  3.2515e-02, -6.5235e-08, -2.8595e-13,\n",
       "                        2.7519e-02,  5.9880e-02, -1.3798e-11,  7.5368e-02,  4.5166e-02,\n",
       "                       -1.4504e-06,  5.0198e-02,  2.3284e-02,  7.0301e-02,  2.5129e-02,\n",
       "                       -8.1126e-06,  6.5084e-02,  3.5419e-02, -1.1469e-04,  5.9071e-02,\n",
       "                        6.2706e-02,  7.9560e-02, -2.8165e-05,  5.1321e-02, -1.0686e-04,\n",
       "                       -1.6462e-09,  4.3035e-02, -6.9797e-10,  5.6022e-02, -1.0126e-06,\n",
       "                        6.5602e-02,  8.0163e-02,  5.3652e-02, -7.5451e-11,  2.4436e-02,\n",
       "                        6.3718e-02, -4.6076e-07,  2.9755e-02,  3.1191e-02,  2.8404e-02,\n",
       "                        6.9071e-02,  4.0727e-02,  6.1856e-02,  8.2760e-02,  7.5649e-02,\n",
       "                        6.4113e-02,  3.3316e-02,  5.2472e-02, -4.3504e-06, -1.2488e-15,\n",
       "                        8.0466e-20,  7.9996e-02,  6.7138e-02,  8.1621e-02,  8.7643e-02,\n",
       "                        2.9460e-02,  8.3487e-02, -2.3225e-05, -1.3638e-03, -1.3734e-11,\n",
       "                        4.7218e-02, -1.1845e-06,  7.3310e-02, -2.4803e-15,  6.8741e-02,\n",
       "                        6.0122e-02,  4.1876e-02,  2.5450e-02, -4.1104e-14,  7.9949e-02,\n",
       "                       -2.0541e-07,  4.1682e-02,  7.8043e-02,  7.4434e-02, -3.3518e-06,\n",
       "                       -2.8016e-10,  8.7214e-02, -1.7206e-08,  6.3250e-02,  3.4940e-02,\n",
       "                        5.1874e-02,  6.3612e-02,  3.2461e-02,  6.5547e-02,  6.9411e-02,\n",
       "                       -5.4253e-10,  5.2467e-02,  4.1552e-02, -7.8916e-16,  5.4916e-02,\n",
       "                       -1.5703e-06, -7.1263e-07,  6.3763e-02,  5.7091e-02,  4.2968e-02,\n",
       "                       -2.6293e-09,  4.9819e-02,  8.6114e-02,  2.1062e-02, -5.5978e-07,\n",
       "                        6.2875e-02,  6.0619e-02, -2.7264e-13,  6.2094e-02,  5.0635e-02,\n",
       "                       -6.1624e-10,  7.1959e-02,  6.2700e-02,  5.4105e-02,  5.5230e-02,\n",
       "                       -2.3412e-06, -1.4075e-06, -1.1126e-16, -4.0790e-08,  4.3698e-02,\n",
       "                        6.7420e-02,  6.3400e-02,  9.0176e-02, -1.9569e-05,  7.0011e-02,\n",
       "                        1.8778e-02, -1.8895e-06, -7.4638e-13, -2.5036e-06,  1.2114e-01,\n",
       "                       -3.6609e-11,  7.6110e-02, -4.0749e-14,  3.7810e-02,  6.0536e-02,\n",
       "                       -9.8358e-10,  3.9327e-02,  4.8716e-02,  2.2517e-02,  7.4548e-02,\n",
       "                        6.9498e-02,  7.8253e-02,  3.9131e-02,  5.8784e-02,  2.2282e-02,\n",
       "                        4.9494e-02,  2.7064e-02,  6.4128e-02,  7.8507e-02,  5.2711e-02,\n",
       "                       -2.1344e-06,  8.2929e-02, -1.4805e-16, -3.0329e-07,  6.9372e-02,\n",
       "                        6.7117e-08, -2.3766e-11, -6.1336e-07,  2.5938e-02,  6.0318e-02,\n",
       "                        3.0868e-02,  4.5531e-02,  2.3466e-02,  3.2982e-02, -2.2815e-15,\n",
       "                       -1.8203e-07,  6.0433e-02,  5.8987e-02,  6.4012e-02,  5.0392e-02,\n",
       "                        2.3952e-02,  8.3901e-02,  3.3721e-02,  5.2110e-02,  5.4727e-02,\n",
       "                        7.9330e-02, -2.8546e-11,  5.1827e-02, -6.5060e-13,  7.1904e-02,\n",
       "                        1.8272e-02,  7.7475e-02, -2.0752e-09,  2.6418e-02,  6.9829e-02,\n",
       "                       -4.1499e-10,  8.2464e-02, -2.1807e-08,  5.6041e-02, -3.3407e-13,\n",
       "                       -2.1249e-06,  5.6147e-02,  4.4460e-02,  4.7269e-02,  8.7786e-02,\n",
       "                       -2.3037e-12,  8.6084e-02,  4.5217e-02,  7.5351e-02,  3.5636e-02,\n",
       "                        2.0047e-02,  1.5514e-02,  7.7020e-02,  5.7859e-02, -1.8861e-18,\n",
       "                       -2.0651e-08,  8.6571e-02,  6.7625e-02,  5.8754e-02,  7.2287e-02,\n",
       "                        6.1668e-02,  3.1783e-02, -2.1053e-14, -3.0059e-06,  3.5737e-02,\n",
       "                       -4.5709e-10,  4.1972e-02,  4.1692e-02, -8.8228e-07,  6.2883e-02,\n",
       "                       -7.5075e-07,  3.1457e-02,  6.8250e-02,  2.9638e-02,  6.5218e-02,\n",
       "                        3.9756e-02,  5.5856e-02,  4.6395e-02, -9.6945e-12, -7.6311e-18,\n",
       "                        5.9781e-02,  5.5049e-02, -9.7164e-21,  2.0045e-02,  5.5690e-02,\n",
       "                        7.0586e-02,  2.7255e-02,  5.6505e-02,  1.9936e-02, -3.7783e-08,\n",
       "                        5.5852e-08, -6.7118e-10,  4.3142e-02,  2.4606e-02,  5.3265e-02,\n",
       "                       -1.0934e-08,  8.4972e-02,  8.7631e-02, -8.6171e-09, -6.1251e-10,\n",
       "                        8.8570e-02, -2.1438e-10,  3.2443e-17, -2.9639e-15,  3.2398e-02,\n",
       "                        4.0080e-02,  4.1602e-02, -6.1103e-08,  6.1367e-02, -2.9280e-06,\n",
       "                        4.0392e-02,  4.9848e-17, -2.5370e-14,  5.7190e-02,  7.4338e-02,\n",
       "                       -3.3131e-18,  3.5082e-02,  5.0562e-02, -1.2744e-03,  2.8607e-02,\n",
       "                       -2.3157e-14,  2.1054e-11,  2.5894e-02,  7.1436e-02,  2.5852e-02,\n",
       "                       -8.6478e-05,  6.9853e-02,  4.7537e-02,  4.0804e-02,  6.1618e-02,\n",
       "                       -5.7725e-16, -5.2112e-08, -1.5750e-13,  3.3639e-02, -1.9185e-11,\n",
       "                        3.9437e-02, -6.1170e-12,  6.4482e-02,  3.2689e-02,  8.1856e-02,\n",
       "                        4.2996e-02, -1.2747e-06, -3.2620e-09, -8.3776e-09, -1.4212e-13,\n",
       "                        3.7677e-02, -8.5637e-11,  4.4712e-02,  7.6568e-02, -2.1074e-08,\n",
       "                        5.0322e-02, -1.6470e-03,  5.0315e-02,  4.6592e-02,  6.7161e-02,\n",
       "                        6.4010e-02,  4.3537e-02,  2.2475e-02,  7.9211e-02, -1.6111e-05,\n",
       "                        4.7639e-02, -8.8530e-07,  1.6676e-02,  1.1128e-02,  4.7195e-02,\n",
       "                        7.5453e-02,  5.0232e-02, -1.6151e-08, -2.0540e-06,  4.1553e-02,\n",
       "                        2.8394e-02,  4.2172e-02, -1.1996e-10,  8.4083e-02, -7.5698e-12,\n",
       "                       -1.7643e-10,  5.4627e-02, -7.1753e-13, -2.0867e-05,  5.1438e-02,\n",
       "                        8.4989e-02,  5.5340e-02,  4.8729e-02,  5.8372e-02,  5.0376e-02,\n",
       "                       -1.9384e-07,  3.0879e-02,  7.0410e-02, -8.4937e-13, -1.0101e-09,\n",
       "                       -3.5324e-13, -2.4443e-18,  8.7368e-02, -5.3777e-07,  6.5911e-02,\n",
       "                        4.0098e-02,  2.3377e-02,  8.0867e-02, -1.8032e-07, -6.2155e-13,\n",
       "                        2.9811e-02, -5.2513e-11,  4.4783e-02,  7.2360e-02, -2.2823e-07,\n",
       "                       -4.5291e-08, -4.4151e-10,  6.0887e-02, -6.5744e-09,  6.5517e-02,\n",
       "                        5.3060e-02, -2.5381e-08,  8.9086e-13,  5.3205e-02,  5.9674e-02,\n",
       "                        2.5781e-02, -3.6473e-13, -4.5099e-09, -2.5327e-17, -2.0839e-13,\n",
       "                        3.7200e-02,  2.5256e-02,  7.0448e-02,  7.0343e-02, -8.4140e-11,\n",
       "                        4.4549e-02,  3.0281e-02,  6.2626e-02,  6.5058e-02,  2.7194e-02,\n",
       "                        6.4550e-02,  7.0611e-02,  7.7576e-02,  5.5877e-02, -3.5590e-09,\n",
       "                        7.1517e-02,  5.8778e-02,  6.9995e-02, -1.7406e-07,  2.4630e-02,\n",
       "                        5.9300e-02,  4.0505e-02,  5.6820e-02,  3.4271e-02,  9.2238e-02,\n",
       "                        3.0008e-02, -9.7557e-10, -3.4055e-07, -5.5113e-10, -8.3368e-09,\n",
       "                        5.2346e-02,  7.9617e-02, -1.9034e-14, -5.8656e-05,  5.3322e-02,\n",
       "                        5.8777e-02,  8.7429e-02,  3.6498e-02,  1.0727e-11, -4.8640e-08,\n",
       "                        3.9812e-02,  6.5632e-02,  8.4458e-02,  3.9517e-02,  4.5098e-02,\n",
       "                       -8.2714e-07,  5.3194e-02, -1.7748e-04,  7.9524e-02,  6.1795e-02,\n",
       "                        3.8678e-08, -1.3562e-06,  3.6177e-02, -1.7756e-08,  6.2948e-02,\n",
       "                        6.2271e-03,  5.7648e-02,  6.7299e-02,  6.3509e-02,  6.0040e-02,\n",
       "                       -1.3423e-04,  6.3177e-02,  5.0556e-02,  8.0509e-02,  8.7031e-02],\n",
       "                      device='mps:0')),\n",
       "              ('fc3.weight',\n",
       "               tensor([[ 4.9913e-01,  3.6855e-05,  9.6760e-02,  ..., -1.2233e-01,\n",
       "                        -2.6044e-01, -2.4605e-01],\n",
       "                       [-3.0973e-01, -1.4292e-04, -2.0573e-01,  ...,  2.1956e-01,\n",
       "                         3.3259e-01, -1.4892e-01],\n",
       "                       [-3.2201e-01,  7.9743e-07,  1.4763e-02,  ..., -1.3816e-01,\n",
       "                        -1.9018e-01,  3.1717e-01]], device='mps:0')),\n",
       "              ('fc3.bias',\n",
       "               tensor([-0.0042,  0.0280,  0.0283], device='mps:0'))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 1290},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 1290,\n",
       "     'completed': 1290,\n",
       "     'started': 1290,\n",
       "     'processed': 1290},\n",
       "    'current': {'ready': 129,\n",
       "     'completed': 129,\n",
       "     'started': 129,\n",
       "     'processed': 129},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 1290,\n",
       "       'completed': 1290},\n",
       "      'current': {'ready': 129, 'completed': 129}},\n",
       "     'zero_grad': {'total': {'ready': 1290,\n",
       "       'completed': 1290,\n",
       "       'started': 1290},\n",
       "      'current': {'ready': 129, 'completed': 129, 'started': 129}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 43,\n",
       "     'completed': 43,\n",
       "     'started': 43,\n",
       "     'processed': 43},\n",
       "    'current': {'ready': 43, 'completed': 43, 'started': 43, 'processed': 43},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 10,\n",
       "     'completed': 9,\n",
       "     'started': 10,\n",
       "     'processed': 10},\n",
       "    'current': {'ready': 10, 'completed': 9, 'started': 10, 'processed': 10}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\": {'wait_count': 8,\n",
       "   'stopped_epoch': 9,\n",
       "   'best_score': tensor(0.7119, device='mps:0'),\n",
       "   'patience': 5},\n",
       "  \"ModelCheckpoint{'monitor': 'val_loss', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': 'val_loss',\n",
       "   'best_model_score': tensor(1.0822, device='mps:0'),\n",
       "   'best_model_path': '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=9-val_f1score=0.683.ckpt',\n",
       "   'current_score': tensor(1.0822, device='mps:0'),\n",
       "   'dirpath': '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe',\n",
       "   'best_k_models': {'/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=9-val_f1score=0.683.ckpt': tensor(1.0822, device='mps:0')},\n",
       "   'kth_best_model_path': '/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=9-val_f1score=0.683.ckpt',\n",
       "   'kth_value': tensor(1.0822, device='mps:0'),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(1290.),\n",
       "     'exp_avg': tensor([[-1.6533e-05,  2.7584e-06, -2.1200e-36,  ...,  2.1653e-33,\n",
       "               1.7092e-33,  6.9840e-07],\n",
       "             [-1.5941e-05, -2.7085e-06, -4.9587e-07,  ...,  3.3182e-37,\n",
       "               6.3671e-09, -3.9679e-06],\n",
       "             [ 4.0230e-07,  4.6817e-08, -8.8700e-21,  ..., -1.7246e-25,\n",
       "               3.2716e-09,  1.6246e-07],\n",
       "             ...,\n",
       "             [ 1.8370e-07,  7.8259e-13,  6.8736e-25,  ...,  2.7965e-28,\n",
       "              -1.8623e-09, -1.0441e-07],\n",
       "             [-4.1058e-07,  1.2547e-08,  9.1064e-07,  ...,  4.7919e-20,\n",
       "              -1.3573e-16,  9.3915e-07],\n",
       "             [-4.3759e-07, -2.0030e-06, -1.2623e-30,  ...,  3.2701e-35,\n",
       "              -1.2933e-27,  8.7775e-10]], device='mps:0'),\n",
       "     'exp_avg_sq': tensor([[5.8558e-08, 1.9569e-08, 2.4161e-12,  ..., 8.3208e-14, 8.3783e-13,\n",
       "              6.8189e-09],\n",
       "             [8.3056e-08, 6.8350e-08, 2.6005e-09,  ..., 1.0794e-15, 2.3599e-11,\n",
       "              1.7916e-08],\n",
       "             [9.9191e-10, 5.0634e-10, 2.1826e-10,  ..., 2.2469e-13, 5.3848e-13,\n",
       "              7.0859e-10],\n",
       "             ...,\n",
       "             [2.5509e-09, 8.4855e-10, 2.0210e-11,  ..., 4.9025e-13, 1.8299e-11,\n",
       "              1.2967e-09],\n",
       "             [2.4078e-09, 1.2214e-09, 6.0429e-10,  ..., 5.5731e-13, 3.3269e-11,\n",
       "              1.3686e-09],\n",
       "             [1.6323e-09, 9.2325e-10, 3.6289e-11,  ..., 4.7426e-13, 3.1687e-14,\n",
       "              5.3816e-09]], device='mps:0')},\n",
       "    1: {'step': tensor(1290.),\n",
       "     'exp_avg': tensor([ 7.8735e-04,  2.5985e-03,  6.9178e-05,  8.6524e-05, -2.3443e-04,\n",
       "             -1.3011e-04,  2.4588e-05,  1.0634e-03, -2.0396e-06,  1.2507e-04,\n",
       "             -4.2889e-06, -1.0569e-03, -5.7685e-06,  2.6039e-04,  5.3135e-06,\n",
       "              3.1586e-03, -8.6722e-07, -1.9649e-06, -1.4450e-06, -9.4621e-04,\n",
       "              1.5093e-06,  2.2094e-04,  4.1074e-06,  3.2478e-04, -3.1694e-03,\n",
       "              9.4723e-04, -8.1803e-05, -3.1134e-06,  3.3862e-05, -1.3275e-05,\n",
       "              3.6539e-04,  2.3020e-03, -7.6851e-04,  4.1020e-05,  3.6870e-05,\n",
       "             -1.8799e-03, -3.8512e-03,  2.5821e-04,  2.0687e-04,  1.3868e-05,\n",
       "              6.9622e-04,  1.6297e-05,  1.1296e-04, -1.2529e-07, -5.2415e-07,\n",
       "             -1.0259e-05, -6.2972e-06,  9.3829e-05, -2.8892e-07,  9.4653e-04,\n",
       "             -9.1460e-06, -3.8736e-06, -6.2037e-04, -2.2588e-06, -2.3550e-03,\n",
       "              2.6763e-06,  8.0323e-04,  6.0076e-06,  4.6963e-05,  1.9832e-05,\n",
       "             -2.9261e-06, -1.5152e-03,  1.4000e-03, -1.3589e-03, -3.9731e-03,\n",
       "             -6.8581e-03,  6.4328e-05, -1.9736e-06,  5.9460e-04,  2.5091e-04,\n",
       "              1.9575e-04,  3.2532e-03,  1.4617e-04,  3.2788e-04,  1.6022e-04,\n",
       "              7.3427e-05, -1.6469e-03,  1.0871e-03,  1.1169e-03, -1.7976e-07,\n",
       "              2.7126e-03,  3.7828e-04,  4.3597e-05,  6.2290e-05,  4.4875e-04,\n",
       "             -1.2668e-06,  2.7914e-04,  3.0086e-04, -5.1020e-04,  1.4992e-05,\n",
       "              8.0129e-05, -1.0912e-04, -2.0107e-04,  2.2585e-04,  9.3213e-06,\n",
       "             -1.3810e-03, -3.3346e-06,  2.0717e-05, -3.9873e-04,  2.6546e-05,\n",
       "              5.9795e-05,  6.5741e-05,  1.2991e-04, -8.2813e-06, -1.7526e-04,\n",
       "              5.4472e-07,  2.6746e-03, -2.5075e-03,  6.0381e-04,  5.9861e-04,\n",
       "              1.0267e-04,  2.2047e-05, -4.5085e-05, -1.9993e-07,  4.5061e-06,\n",
       "             -3.5249e-03,  4.3549e-03, -1.8121e-06, -1.0827e-05, -3.1944e-06,\n",
       "             -4.9645e-06,  2.6369e-03, -5.3021e-06,  1.7464e-03,  1.1160e-04,\n",
       "             -7.7748e-05, -1.8022e-03,  9.4962e-05, -3.6440e-05, -9.9147e-05,\n",
       "             -1.7472e-04,  2.1629e-05,  2.5895e-03,  9.2093e-04, -4.1090e-06,\n",
       "              7.2285e-05, -1.0637e-04,  1.5260e-05, -2.8429e-03, -7.8310e-07,\n",
       "             -5.6633e-03, -8.0176e-06,  7.2739e-04, -2.8465e-06,  7.4318e-05,\n",
       "              1.2747e-06,  4.7880e-04, -2.0938e-09, -4.6593e-10,  1.7795e-05,\n",
       "             -1.1830e-05,  3.3031e-03,  2.6555e-06, -3.5430e-06, -2.1126e-03,\n",
       "              2.2762e-05,  1.1026e-04, -3.4219e-04, -7.4395e-06, -2.6694e-03,\n",
       "             -2.6756e-05, -3.2068e-06,  2.7268e-06, -8.4419e-05,  3.4284e-03,\n",
       "             -3.2380e-07, -7.1851e-04, -2.6348e-04, -2.7619e-06,  4.8814e-04,\n",
       "              1.3739e-05, -1.5239e-06,  1.8358e-04, -3.3023e-04, -7.9941e-06,\n",
       "             -8.5016e-04, -5.5152e-07, -2.6256e-06, -1.3237e-05,  1.1219e-05,\n",
       "              4.8613e-05,  4.6126e-04, -9.7803e-07,  2.1393e-03, -1.7819e-06,\n",
       "              8.2770e-04, -3.1574e-04,  1.3263e-04,  3.1271e-04, -1.9025e-06,\n",
       "              6.7315e-07,  2.3843e-04,  3.7208e-04, -2.7579e-03, -2.2635e-07,\n",
       "              1.6786e-03,  1.4138e-04,  5.0839e-05, -1.4270e-07, -1.7186e-06,\n",
       "              6.2678e-04, -2.8161e-04, -3.4192e-03,  2.8884e-04, -1.2979e-06,\n",
       "             -1.0722e-04, -6.2100e-05, -1.6732e-05, -6.8922e-07, -2.2402e-04,\n",
       "              2.1977e-05,  1.3395e-05,  5.9131e-04,  1.8300e-06, -2.0002e-06,\n",
       "              2.1899e-04, -1.1360e-05, -2.8970e-06,  3.7544e-06, -2.2047e-03,\n",
       "             -8.4184e-06, -3.3041e-03, -2.2222e-03, -2.3851e-03,  8.3243e-04,\n",
       "             -2.6056e-07, -4.7973e-10,  8.8032e-05,  7.4296e-04, -2.9741e-06,\n",
       "              3.7963e-05,  1.1098e-04,  3.4209e-03,  2.3965e-05,  1.3813e-03,\n",
       "             -1.4405e-03,  2.7777e-05, -1.0818e-06, -8.2640e-05,  8.5355e-06,\n",
       "             -6.6240e-04, -8.3626e-03, -2.7783e-05,  1.1978e-03,  3.9115e-04,\n",
       "             -6.3957e-03, -7.7231e-06,  8.7689e-05,  8.9200e-06,  1.9530e-03,\n",
       "              2.9947e-03,  5.5597e-04,  8.7216e-04, -4.4671e-03,  1.0586e-04,\n",
       "             -1.2459e-07, -5.1313e-07, -3.0047e-05,  3.1364e-04,  1.8368e-05,\n",
       "             -9.1412e-06, -1.4345e-07,  6.2359e-04, -1.3991e-04,  1.8016e-04,\n",
       "             -2.8671e-06,  7.3442e-05,  5.7733e-04, -2.6509e-04,  3.4154e-05,\n",
       "             -2.2421e-03,  3.9723e-06,  1.0844e-04,  4.7438e-04, -2.2919e-04,\n",
       "             -2.3960e-04,  5.0345e-05, -6.4588e-04,  4.9220e-04, -5.8720e-07,\n",
       "              3.0867e-05, -2.0936e-06, -5.8246e-05,  2.1613e-03,  3.5250e-05,\n",
       "              2.4926e-05, -4.4771e-07,  1.0394e-04, -9.6216e-04,  9.3642e-06,\n",
       "              4.5125e-05,  4.2790e-05, -5.9159e-04,  1.0961e-04,  1.3280e-04,\n",
       "              1.2874e-03, -2.9900e-04,  1.4572e-02,  1.0797e-03, -8.3393e-04,\n",
       "             -1.7609e-09,  2.8663e-05,  3.8568e-04,  1.4884e-03, -4.7225e-03,\n",
       "             -3.9965e-04, -2.8763e-03,  5.9394e-05, -2.6795e-05,  5.5300e-04,\n",
       "              1.1857e-05, -4.4489e-06, -6.0484e-03,  5.3493e-05,  1.6959e-03,\n",
       "              1.1488e-03, -2.5132e-05, -1.3468e-02, -2.5030e-06, -4.0981e-06,\n",
       "              1.7135e-05, -9.7493e-05,  9.5263e-06,  7.3725e-05,  2.1681e-03,\n",
       "              1.3937e-05,  3.0229e-04, -5.2140e-07,  2.8721e-05, -8.1971e-06,\n",
       "              3.4354e-05,  6.0379e-04,  3.9628e-03,  3.1067e-04,  1.8471e-04,\n",
       "             -8.3276e-05,  1.2952e-04,  4.9161e-05, -2.1096e-06,  7.4410e-04,\n",
       "              4.9889e-06, -6.5641e-04, -1.3795e-03, -1.7415e-04, -1.0113e-05,\n",
       "             -2.3232e-04, -4.2052e-03, -9.6882e-04, -1.0262e-06, -2.9739e-06,\n",
       "             -2.4620e-03, -4.8277e-04, -1.6689e-04,  5.4274e-05,  2.8214e-06,\n",
       "             -1.3761e-04, -3.2112e-06, -1.1917e-05,  2.7069e-04,  2.5937e-05,\n",
       "              1.4674e-03,  4.0811e-05, -7.6120e-07,  1.4670e-04,  1.2757e-03,\n",
       "              6.7592e-05,  6.3396e-03, -6.9007e-04, -1.0650e-06,  4.5117e-04,\n",
       "             -7.2868e-07, -1.8757e-06, -1.4649e-05,  1.3682e-04, -2.5899e-04,\n",
       "             -2.3804e-03,  7.8429e-04, -2.5974e-06, -1.6234e-04, -2.1533e-03,\n",
       "             -9.7101e-03, -2.5303e-03, -1.1394e-04,  2.8583e-04,  1.1728e-03,\n",
       "             -5.8576e-06, -3.2753e-11, -3.9597e-05,  1.2915e-04,  7.9433e-06,\n",
       "             -9.2687e-07,  4.8962e-03,  1.7573e-03, -3.0833e-04,  8.5115e-03,\n",
       "              7.1563e-06,  1.2102e-05,  1.7355e-03,  1.2703e-05,  4.5520e-04,\n",
       "             -1.6218e-03,  4.6356e-04, -1.2809e-05, -3.5250e-03, -6.2978e-04,\n",
       "             -3.8518e-04,  2.8318e-04, -7.5336e-04, -1.1634e-04,  5.6036e-04,\n",
       "              4.4127e-04, -4.2840e-06,  1.0011e-04, -3.7797e-06, -2.6606e-06,\n",
       "              7.6522e-05,  6.1473e-04, -1.1513e-03,  1.3357e-04, -2.9269e-03,\n",
       "              2.9661e-04,  2.6505e-04,  4.0444e-04, -1.8561e-04, -4.4133e-06,\n",
       "             -8.4334e-07, -1.0983e-03,  4.6530e-03,  3.0604e-04, -3.8392e-03,\n",
       "              6.0108e-05, -3.6309e-05, -4.7526e-06, -9.6470e-04, -2.2084e-03,\n",
       "              3.6363e-04, -7.7519e-04, -6.3471e-05, -9.9486e-05, -3.2363e-03,\n",
       "             -2.6820e-03,  1.7706e-03,  5.9185e-04,  4.3014e-04,  1.9375e-05,\n",
       "             -1.3828e-03, -1.5483e-06, -7.2204e-06, -2.8103e-05, -7.6403e-04,\n",
       "              9.5959e-04, -6.2992e-06,  1.1878e-04,  7.7061e-04,  4.3595e-04,\n",
       "              1.9037e-04, -3.6318e-05,  2.4532e-06, -8.7948e-06,  2.3004e-05,\n",
       "             -6.6208e-04, -1.4450e-04,  1.4698e-04, -2.3883e-07,  1.2082e-04,\n",
       "              1.1200e-04,  1.7166e-03, -5.0113e-06,  1.2995e-04,  6.7288e-04,\n",
       "             -1.9130e-06, -1.1497e-05,  4.4073e-05, -1.1331e-05,  1.3146e-04,\n",
       "              8.1246e-06, -6.9293e-03,  1.5448e-05, -5.9926e-06, -1.2914e-03,\n",
       "              4.3697e-04, -1.0309e-08,  4.0861e-05,  4.3702e-04,  1.5035e-04,\n",
       "             -3.1856e-04, -5.3087e-06, -5.3566e-05,  1.8192e-04,  2.7063e-05,\n",
       "              3.6475e-05, -1.9707e-05,  8.4835e-05, -2.0627e-04, -1.7754e-05,\n",
       "             -1.0979e-05,  5.0088e-05, -5.8950e-05, -2.5024e-07,  5.5789e-05,\n",
       "             -3.2133e-03,  1.6544e-05,  1.5897e-03, -4.0819e-04,  2.3719e-05,\n",
       "             -1.9897e-05, -2.9306e-06,  1.9575e-04, -9.9523e-03, -4.6783e-05,\n",
       "             -5.8269e-04, -2.4030e-05, -3.1398e-07,  6.5566e-05, -1.2169e-03,\n",
       "              2.2429e-05, -5.9251e-06, -1.8564e-06,  1.9463e-05,  4.1253e-04,\n",
       "             -7.0114e-04, -3.7042e-03, -1.0183e-06,  3.7031e-05, -1.1180e-03,\n",
       "              1.5077e-05, -4.1495e-06,  7.7778e-05,  3.8798e-05,  2.6878e-03,\n",
       "              1.7476e-03, -2.7527e-04,  7.1871e-07,  5.2885e-05,  4.3178e-04,\n",
       "              5.9936e-04, -2.3217e-06, -8.9973e-04,  3.7506e-15,  5.2946e-05,\n",
       "             -8.6097e-06,  7.3177e-04, -2.2697e-07,  5.2500e-05, -4.8982e-06,\n",
       "             -5.3106e-05, -2.6602e-05,  7.0161e-05, -2.9611e-04,  4.7622e-05,\n",
       "              7.5125e-05,  2.7927e-03,  3.2897e-05,  2.5797e-03,  6.6847e-05,\n",
       "             -7.8803e-12, -1.3440e-05, -4.6898e-04,  3.9187e-05,  6.7540e-04,\n",
       "              4.7258e-03, -8.8598e-04, -8.5300e-05,  1.1764e-03, -1.7166e-05,\n",
       "             -5.3941e-05, -2.1690e-04,  2.1799e-03, -2.5447e-04,  3.5757e-06,\n",
       "             -6.1321e-03, -2.2045e-06, -1.9925e-05, -1.4259e-04, -1.0954e-03,\n",
       "              4.9423e-04, -1.2904e-04,  1.1030e-03,  1.2855e-03, -5.7782e-06,\n",
       "              2.0075e-03,  6.5550e-04,  8.1069e-04, -2.5914e-06, -1.9017e-04,\n",
       "             -6.6006e-08,  2.4615e-04, -4.5194e-06,  3.3073e-05,  1.9675e-05,\n",
       "              1.1887e-03,  1.4429e-04,  6.4475e-06, -2.4278e-04, -2.1158e-06,\n",
       "             -6.3272e-06,  5.5838e-05, -1.3945e-03,  6.1111e-05, -7.9012e-04,\n",
       "              2.6277e-03,  4.0766e-05, -6.0273e-06, -3.2624e-05, -2.4085e-05,\n",
       "             -7.9144e-04, -1.1993e-07, -9.6387e-04, -3.6318e-03,  1.0088e-04,\n",
       "             -2.3042e-04,  1.8041e-03, -2.7174e-03, -7.7395e-06,  9.2184e-06,\n",
       "             -3.5214e-05,  9.8217e-05, -1.9473e-05,  1.6630e-05,  8.1605e-05,\n",
       "              1.7664e-05, -1.2397e-03,  4.6757e-04,  1.3674e-06, -4.8293e-06,\n",
       "             -1.5867e-06, -1.3190e-04,  1.3297e-05, -8.2304e-05,  4.5319e-03,\n",
       "              2.8059e-05, -4.2616e-03, -2.1495e-03,  3.4966e-05,  2.1172e-04,\n",
       "             -1.1815e-05, -4.0693e-06, -3.0933e-04, -1.0047e-05, -8.9143e-05,\n",
       "              6.9603e-04, -9.6606e-04,  3.6120e-04,  9.3287e-06, -1.1059e-03,\n",
       "             -2.5660e-07, -4.5343e-06,  5.5138e-03, -2.2981e-04, -8.3842e-03,\n",
       "             -5.0943e-05,  2.3041e-03,  5.9449e-04, -6.8397e-07, -2.8136e-03,\n",
       "              3.0214e-03, -9.1674e-11, -3.0651e-06, -1.5992e-06, -5.7582e-06,\n",
       "             -1.8132e-02,  5.4773e-05,  6.0657e-04, -1.6973e-03,  1.8091e-03,\n",
       "              4.7765e-04, -3.9101e-09,  1.9194e-05, -1.4209e-03,  1.4155e-03,\n",
       "             -1.0683e-05, -1.9054e-06, -7.6815e-05, -5.3689e-04,  6.5293e-04,\n",
       "             -1.2760e-05, -1.1909e-05, -7.6707e-05,  1.5721e-03,  6.8431e-04,\n",
       "             -9.3034e-04, -7.2256e-06, -1.5346e-03,  4.5131e-05,  4.7693e-06,\n",
       "              2.6276e-03, -2.6437e-06,  4.7096e-03,  3.5446e-06,  2.0760e-04,\n",
       "              1.2950e-03,  2.3884e-05,  8.2510e-05,  1.6093e-03,  2.6570e-05,\n",
       "             -5.2240e-04,  4.1656e-06, -1.4741e-05,  2.3184e-06, -8.4227e-03,\n",
       "             -9.9505e-07, -5.9620e-06,  4.9003e-05, -1.3680e-06, -2.7733e-05,\n",
       "              7.1168e-06,  1.1737e-04,  1.0767e-04,  1.9297e-06,  8.3385e-05,\n",
       "             -2.5196e-05, -3.4697e-03,  1.4760e-04,  4.5621e-06, -1.4916e-04,\n",
       "             -9.0276e-08,  2.0425e-05, -1.6604e-06,  2.4260e-06, -5.1710e-06,\n",
       "              1.7493e-03,  4.7812e-05, -1.5317e-07,  7.2699e-04,  6.0402e-06,\n",
       "             -1.3708e-05, -1.1017e-03, -4.0455e-07,  1.0973e-05,  2.1949e-05,\n",
       "             -1.3857e-04,  2.0292e-04, -6.0770e-03,  7.3778e-05,  3.3813e-05,\n",
       "              1.0965e-03, -2.0638e-05,  1.8946e-04, -1.6712e-03, -4.3442e-05,\n",
       "             -1.2161e-04, -2.6838e-05, -2.9531e-06,  8.4282e-06,  1.8302e-06,\n",
       "              3.8769e-06,  4.4035e-03, -5.3188e-04,  1.6781e-03, -1.8334e-04,\n",
       "              5.6982e-03,  6.6894e-06,  1.2434e-04, -4.4443e-04, -1.8957e-04,\n",
       "              1.6298e-03, -1.7771e-03,  8.7391e-04, -1.9031e-03,  7.4458e-05,\n",
       "             -1.0367e-05, -9.0385e-09, -8.6814e-04, -1.3156e-06, -3.1659e-06,\n",
       "              3.4504e-06, -3.2770e-06,  1.1592e-04, -3.8237e-04,  1.7559e-03,\n",
       "             -4.2691e-06,  4.5295e-04,  1.8120e-05,  8.6663e-04, -1.6452e-06,\n",
       "              2.3395e-05, -1.8466e-05,  1.2430e-03, -2.5128e-03,  6.5397e-05,\n",
       "             -2.4953e-06, -1.1980e-05, -1.8300e-05, -3.8689e-05, -3.5506e-06,\n",
       "              7.3769e-05, -1.9391e-05, -3.1688e-06,  6.4921e-04, -1.5863e-04,\n",
       "             -1.2926e-04,  1.3852e-04,  1.3729e-03, -8.5846e-07, -1.0285e-03,\n",
       "              3.9239e-07,  5.6389e-07,  7.0178e-04,  1.2245e-05, -1.0396e-03,\n",
       "             -2.0213e-06,  5.8843e-03, -7.2952e-05, -5.1600e-07,  2.9750e-03,\n",
       "             -1.7117e-03,  2.5301e-04, -1.7627e-06, -4.1088e-06, -5.7301e-05,\n",
       "              1.0967e-05, -1.8591e-04,  3.4791e-04, -1.6485e-06, -1.1701e-04,\n",
       "             -1.9505e-05,  8.3368e-04,  1.3502e-04, -1.5316e-08,  4.6338e-05,\n",
       "             -1.3732e-04,  4.5673e-06,  9.2081e-05, -2.0496e-06,  3.3916e-03,\n",
       "              1.8788e-04, -1.0146e-02,  3.6650e-04, -4.6209e-04,  1.2866e-05,\n",
       "              6.9796e-06, -2.7080e-13,  1.0179e-05, -4.8079e-06,  1.9549e-06,\n",
       "              4.3917e-04, -3.6794e-08,  9.8926e-04, -4.1492e-07, -6.1983e-06,\n",
       "              3.5223e-05, -5.4067e-04,  1.0480e-03, -5.7317e-05, -3.0266e-06,\n",
       "             -2.5582e-04, -5.7419e-05,  1.2841e-03, -6.1159e-08, -1.7077e-03,\n",
       "              1.4686e-03, -5.8018e-06,  8.9249e-04,  2.9859e-05, -9.4977e-06,\n",
       "             -2.8623e-06,  7.5524e-05,  9.6924e-05,  6.6990e-06, -4.1674e-05,\n",
       "             -3.8701e-04, -2.8124e-08, -2.7160e-04,  2.4547e-05,  8.7213e-04,\n",
       "             -5.1003e-03, -1.8052e-05,  3.3236e-04, -1.9736e-03,  2.4418e-05,\n",
       "              8.5587e-04,  8.6877e-06,  4.7497e-04, -2.3147e-04,  2.9075e-03,\n",
       "             -1.0569e-05,  7.7329e-04,  1.2949e-05,  1.7636e-03,  7.6637e-06,\n",
       "             -1.7853e-07, -4.3901e-03,  1.9726e-03,  3.5007e-06, -1.4035e-05,\n",
       "             -1.6427e-06,  8.6282e-05,  7.1157e-05, -3.2681e-04, -6.7880e-04,\n",
       "             -1.6053e-04, -1.1539e-04, -4.6792e-04,  5.8215e-06, -1.4611e-04,\n",
       "             -1.0455e-05,  1.1665e-03, -3.4058e-05,  1.4892e-06, -1.7023e-04,\n",
       "             -2.6173e-06,  4.7171e-04, -5.6199e-06,  2.6193e-04,  2.3969e-05,\n",
       "              1.4518e-04,  1.3290e-05, -6.6789e-06,  1.1625e-03,  1.3246e-03,\n",
       "             -8.3589e-06,  1.9559e-05, -4.0506e-05,  3.0734e-04,  1.0765e-06,\n",
       "              8.4455e-06, -1.1051e-04, -4.1553e-03, -1.0097e-05,  4.6492e-04,\n",
       "             -2.4336e-04,  6.0130e-04,  4.5206e-03, -2.5164e-05, -2.0042e-05,\n",
       "             -2.6568e-04,  2.5263e-05, -4.6007e-06,  3.2725e-04, -5.6801e-04,\n",
       "              3.5231e-05,  5.4277e-05,  1.3533e-03, -9.3777e-08,  1.9730e-04,\n",
       "             -1.2211e-03,  7.8980e-06, -1.3172e-05, -4.6943e-08,  8.5311e-05,\n",
       "              1.5858e-05, -2.1986e-06,  4.0369e-05, -1.2393e-03,  4.9476e-03,\n",
       "              2.3191e-03,  1.2011e-05,  1.5680e-04, -5.0464e-08, -4.6322e-05,\n",
       "              9.0511e-08,  1.0649e-03,  4.0309e-03,  2.7912e-05, -5.4433e-07,\n",
       "             -8.1004e-03, -1.7873e-05, -3.1885e-05, -1.4793e-05,  8.5727e-05,\n",
       "             -3.9374e-05,  6.0419e-04,  2.7699e-08, -4.9506e-03, -2.5676e-06,\n",
       "             -1.9369e-04, -1.5568e-06,  1.0587e-04, -1.5599e-05, -5.3336e-07,\n",
       "              4.6184e-03,  4.1829e-04,  3.8996e-05, -1.7879e-05, -2.6167e-08,\n",
       "             -9.6938e-05,  3.5551e-07,  3.5457e-06, -1.1616e-05, -2.4868e-06,\n",
       "             -3.8197e-05, -7.9491e-04, -2.1517e-06, -2.5149e-05,  7.6057e-04,\n",
       "              3.2148e-05,  1.7486e-03, -1.1565e-05,  2.8744e-05,  1.6909e-04,\n",
       "              8.3020e-05, -1.9219e-05,  1.1306e-03, -2.3361e-03,  3.0399e-05,\n",
       "              1.9085e-03, -1.8164e-03,  4.5419e-06, -3.8312e-04, -1.1251e-04],\n",
       "            device='mps:0'),\n",
       "     'exp_avg_sq': tensor([2.6392e-04, 2.2313e-04, 6.1193e-06, 4.0025e-06, 3.4914e-05, 5.5716e-06,\n",
       "             2.9511e-06, 1.4796e-04, 3.5682e-06, 3.1308e-06, 2.0789e-06, 9.4155e-05,\n",
       "             1.5322e-07, 7.8615e-05, 3.2113e-06, 1.5249e-04, 1.1121e-06, 6.4184e-07,\n",
       "             1.6728e-06, 3.5750e-05, 4.7282e-07, 2.1324e-05, 3.2597e-06, 7.0964e-06,\n",
       "             1.8478e-04, 3.4540e-05, 8.2996e-06, 9.1102e-07, 3.9521e-06, 6.6900e-07,\n",
       "             2.3923e-05, 1.4021e-04, 2.9702e-05, 1.4710e-04, 2.6697e-05, 6.7216e-05,\n",
       "             1.2896e-04, 6.0135e-05, 6.1993e-06, 4.9754e-06, 2.5841e-05, 4.4205e-06,\n",
       "             3.4906e-06, 1.2005e-08, 5.7259e-08, 2.6224e-07, 7.0396e-07, 8.0024e-06,\n",
       "             2.4250e-07, 6.5672e-05, 1.6163e-06, 2.1009e-07, 2.6770e-05, 1.7892e-06,\n",
       "             1.5781e-04, 8.6301e-07, 1.6819e-04, 1.7385e-06, 4.2311e-06, 3.1215e-06,\n",
       "             2.4468e-06, 3.4576e-04, 3.1851e-05, 3.2901e-05, 9.6173e-05, 1.9961e-03,\n",
       "             1.2859e-05, 8.5351e-07, 2.4387e-05, 1.4506e-05, 1.9858e-05, 5.7771e-04,\n",
       "             3.9264e-06, 2.8201e-05, 8.3771e-06, 7.8869e-06, 2.0581e-04, 8.5740e-05,\n",
       "             6.2874e-05, 8.6418e-07, 8.1336e-05, 7.1528e-05, 3.6125e-06, 1.8414e-06,\n",
       "             2.7437e-05, 6.2662e-08, 9.0418e-05, 5.3537e-05, 4.3074e-05, 1.3627e-06,\n",
       "             2.6539e-06, 7.9952e-06, 9.7323e-06, 9.7143e-06, 1.8402e-06, 1.9961e-04,\n",
       "             5.6547e-07, 8.5928e-06, 1.1262e-05, 2.9454e-06, 6.1589e-06, 2.9336e-05,\n",
       "             1.6083e-05, 2.0737e-06, 1.3089e-05, 1.9917e-06, 4.9729e-05, 1.7293e-04,\n",
       "             6.2391e-06, 1.3173e-05, 9.2617e-06, 3.7129e-06, 2.0572e-05, 2.3093e-08,\n",
       "             6.4717e-06, 1.7920e-04, 5.2249e-04, 8.7837e-07, 5.0351e-06, 5.3867e-07,\n",
       "             1.4961e-06, 1.3389e-04, 2.5679e-06, 1.4249e-04, 1.4384e-05, 2.0306e-05,\n",
       "             7.6723e-05, 1.0319e-05, 2.8200e-06, 4.2097e-06, 1.0823e-05, 2.3033e-06,\n",
       "             1.2096e-04, 1.0141e-04, 1.5672e-06, 8.1638e-06, 5.3100e-06, 1.2442e-05,\n",
       "             1.1596e-04, 1.3565e-08, 1.0515e-03, 2.6837e-06, 7.5741e-05, 3.9004e-07,\n",
       "             3.9825e-06, 1.7613e-06, 1.6526e-04, 6.7829e-09, 4.7311e-09, 2.2384e-06,\n",
       "             8.2300e-08, 1.0241e-04, 2.8303e-06, 1.9148e-06, 7.8456e-05, 2.9201e-06,\n",
       "             5.9636e-06, 3.4390e-05, 1.2593e-06, 7.9292e-05, 1.2061e-06, 3.3774e-08,\n",
       "             1.8047e-06, 5.1717e-06, 2.5695e-04, 1.1198e-07, 1.2484e-05, 1.3831e-05,\n",
       "             1.3395e-06, 1.4213e-05, 1.6702e-06, 2.5060e-07, 1.3817e-05, 1.8669e-05,\n",
       "             8.9348e-07, 6.4039e-05, 4.2758e-08, 6.9483e-07, 7.1711e-06, 2.1308e-06,\n",
       "             3.9132e-06, 2.1018e-05, 5.9703e-07, 3.7699e-05, 7.3306e-08, 3.9805e-05,\n",
       "             2.6403e-04, 3.1293e-06, 1.1033e-05, 5.3862e-07, 8.1432e-07, 9.6451e-06,\n",
       "             2.8627e-05, 5.4282e-04, 4.3525e-08, 5.6412e-05, 1.5007e-05, 3.0139e-06,\n",
       "             5.1875e-07, 1.1125e-07, 3.8479e-05, 5.8393e-04, 1.1194e-04, 1.7309e-05,\n",
       "             3.7932e-07, 2.8860e-05, 5.1977e-06, 2.7770e-06, 7.8976e-07, 3.3578e-05,\n",
       "             2.0314e-06, 3.4453e-06, 4.8978e-05, 1.4061e-06, 5.1939e-08, 5.7915e-05,\n",
       "             8.9468e-07, 5.3858e-07, 1.3812e-06, 1.0046e-04, 2.3382e-06, 2.0420e-04,\n",
       "             6.0477e-04, 9.6737e-05, 3.5543e-05, 2.2792e-08, 4.2528e-09, 6.1332e-06,\n",
       "             4.9103e-05, 7.1132e-07, 1.0480e-06, 8.4826e-06, 1.9397e-04, 8.9904e-07,\n",
       "             2.2729e-04, 2.8162e-04, 2.0097e-06, 1.2264e-06, 3.1979e-05, 2.4630e-06,\n",
       "             3.7642e-05, 6.4260e-04, 7.4972e-07, 1.8868e-04, 2.7215e-05, 1.3443e-03,\n",
       "             5.0752e-07, 6.2899e-06, 1.5422e-06, 2.1122e-04, 5.8364e-04, 3.2807e-05,\n",
       "             5.9956e-05, 4.9732e-04, 1.4259e-05, 4.9159e-07, 4.6710e-07, 1.9894e-06,\n",
       "             1.3238e-05, 2.1395e-06, 3.5733e-06, 1.9504e-08, 3.9078e-05, 3.6977e-05,\n",
       "             4.8289e-06, 4.2633e-06, 1.7957e-06, 1.3209e-05, 1.3534e-05, 8.5532e-06,\n",
       "             1.8591e-04, 1.7645e-06, 1.6328e-04, 5.5181e-05, 4.3771e-05, 2.0243e-05,\n",
       "             1.7651e-05, 1.9964e-05, 2.2986e-05, 3.5161e-07, 2.3878e-05, 4.6045e-06,\n",
       "             1.5049e-05, 8.3103e-05, 6.2880e-06, 3.2475e-06, 1.2675e-06, 6.6857e-06,\n",
       "             1.0454e-05, 2.4897e-06, 4.0659e-06, 6.3089e-05, 1.5913e-04, 2.8782e-06,\n",
       "             1.3025e-05, 4.6199e-04, 3.2155e-04, 2.9663e-03, 3.1660e-05, 1.2186e-04,\n",
       "             5.9799e-09, 5.5967e-06, 1.9527e-05, 7.5622e-05, 1.9384e-04, 2.2142e-05,\n",
       "             3.0191e-04, 6.8887e-06, 1.4295e-06, 1.3357e-05, 4.3924e-06, 1.4204e-06,\n",
       "             3.6224e-04, 1.8293e-06, 2.8172e-05, 3.3888e-05, 3.2131e-06, 9.9042e-04,\n",
       "             1.0834e-06, 6.5841e-07, 1.4228e-06, 5.6135e-06, 1.7083e-06, 2.7576e-05,\n",
       "             1.0490e-04, 2.2451e-06, 7.7186e-05, 2.9763e-07, 1.7775e-06, 1.2628e-06,\n",
       "             1.0501e-05, 1.7133e-05, 1.1369e-04, 1.7315e-05, 4.3099e-05, 1.1937e-05,\n",
       "             4.0208e-05, 3.9807e-06, 3.1813e-07, 1.1807e-04, 2.3183e-06, 2.3699e-05,\n",
       "             4.5568e-05, 2.4230e-06, 9.7068e-06, 1.2125e-04, 5.1170e-05, 2.3274e-04,\n",
       "             2.4420e-06, 6.4915e-07, 2.8680e-05, 2.2937e-05, 1.6206e-05, 8.4521e-06,\n",
       "             1.9283e-06, 3.7547e-06, 6.7219e-07, 2.7629e-06, 5.1057e-05, 7.3582e-06,\n",
       "             1.5475e-05, 5.5436e-06, 4.0346e-08, 5.0820e-06, 9.3963e-05, 1.9953e-06,\n",
       "             4.9485e-04, 1.3089e-04, 4.7457e-07, 2.2786e-05, 1.6509e-07, 2.1764e-06,\n",
       "             1.0714e-06, 7.7734e-05, 1.9172e-05, 8.8399e-05, 1.5172e-05, 2.3352e-06,\n",
       "             8.1628e-06, 3.3514e-04, 8.8866e-04, 9.8208e-05, 6.5664e-06, 2.0368e-05,\n",
       "             2.3578e-05, 2.7125e-06, 2.1563e-09, 6.8417e-06, 4.5220e-06, 5.4066e-06,\n",
       "             9.7343e-06, 6.1569e-04, 8.5121e-05, 8.6350e-06, 1.0160e-03, 2.1903e-06,\n",
       "             2.3111e-06, 2.4398e-05, 2.6370e-06, 2.5761e-05, 9.7850e-05, 1.1750e-05,\n",
       "             1.2223e-06, 9.8511e-05, 5.1434e-04, 5.8830e-06, 7.5763e-06, 8.5447e-04,\n",
       "             2.7466e-05, 1.5260e-05, 1.9330e-04, 2.1713e-07, 5.5559e-06, 1.5541e-06,\n",
       "             4.3962e-07, 8.4695e-06, 9.7812e-06, 2.7327e-04, 6.4211e-06, 1.1332e-04,\n",
       "             1.4714e-05, 2.4356e-05, 9.5422e-06, 5.4504e-06, 1.1754e-05, 1.0930e-06,\n",
       "             2.9716e-05, 4.8997e-04, 3.3591e-05, 2.1069e-04, 9.2890e-06, 3.6120e-06,\n",
       "             4.0849e-07, 3.8934e-05, 7.0510e-05, 1.7651e-05, 3.8155e-05, 8.6123e-06,\n",
       "             2.4164e-06, 1.7310e-04, 3.0952e-04, 3.4069e-05, 1.2129e-05, 1.9522e-05,\n",
       "             9.0527e-06, 5.2752e-05, 1.8728e-06, 1.2791e-06, 5.3080e-06, 4.4092e-05,\n",
       "             5.4278e-05, 4.1730e-07, 8.7868e-06, 6.8980e-05, 1.2740e-05, 7.9205e-06,\n",
       "             6.0498e-06, 1.7367e-06, 1.7255e-06, 1.7584e-06, 2.8783e-05, 5.3030e-06,\n",
       "             6.5028e-06, 1.7436e-06, 7.9053e-06, 2.6517e-06, 4.0879e-05, 1.2788e-06,\n",
       "             2.6670e-06, 1.5515e-04, 1.0054e-07, 1.6564e-06, 9.9926e-06, 3.6632e-07,\n",
       "             9.9009e-06, 2.6623e-06, 1.8750e-04, 1.5770e-06, 9.3002e-07, 3.3343e-05,\n",
       "             5.4059e-05, 8.3622e-09, 6.3122e-06, 1.1989e-05, 3.4589e-06, 7.9348e-06,\n",
       "             1.1193e-06, 6.5463e-06, 2.6211e-05, 3.6552e-06, 1.0326e-05, 7.6686e-06,\n",
       "             1.5772e-05, 1.9659e-05, 2.4047e-06, 1.3586e-06, 5.0037e-06, 3.4013e-05,\n",
       "             3.4171e-07, 3.4143e-06, 6.7954e-04, 3.3062e-06, 1.0411e-04, 5.9554e-05,\n",
       "             6.2417e-06, 6.8258e-06, 5.0980e-07, 4.9013e-06, 7.8089e-04, 1.6296e-06,\n",
       "             1.7823e-05, 5.7202e-07, 2.4352e-07, 2.9091e-06, 7.4127e-05, 3.5075e-06,\n",
       "             8.8810e-07, 9.6494e-07, 5.5720e-06, 1.3780e-05, 1.2277e-04, 5.1209e-04,\n",
       "             4.3702e-07, 2.8629e-06, 7.9065e-05, 2.4126e-06, 1.3399e-06, 3.5504e-06,\n",
       "             1.0682e-05, 2.2086e-04, 6.3590e-05, 3.8510e-04, 1.3969e-06, 4.3352e-06,\n",
       "             4.3336e-05, 1.7752e-04, 2.4452e-07, 2.1928e-05, 7.9764e-10, 2.0872e-06,\n",
       "             1.5461e-06, 2.6897e-05, 3.6340e-07, 4.2373e-06, 7.3288e-07, 1.6577e-05,\n",
       "             4.9419e-06, 1.8905e-06, 1.2694e-05, 1.3586e-05, 2.9166e-06, 6.9799e-05,\n",
       "             2.9276e-06, 7.9103e-05, 7.0145e-06, 2.5059e-09, 2.8144e-06, 6.5537e-06,\n",
       "             2.8876e-05, 2.7357e-04, 6.9541e-05, 2.1474e-04, 8.4845e-06, 1.2180e-03,\n",
       "             7.2661e-07, 1.3220e-06, 1.7533e-05, 1.5838e-04, 3.3759e-05, 1.7044e-06,\n",
       "             2.3423e-04, 7.3141e-08, 1.7444e-06, 1.1064e-05, 3.2929e-05, 2.0985e-05,\n",
       "             8.8742e-06, 2.1415e-05, 6.7112e-05, 1.1502e-06, 4.1803e-05, 1.0543e-04,\n",
       "             4.4064e-05, 8.1048e-07, 1.4719e-05, 1.4694e-08, 1.6410e-05, 7.6620e-07,\n",
       "             2.1811e-06, 3.9830e-06, 1.1786e-04, 2.3645e-05, 1.7745e-06, 4.6915e-06,\n",
       "             1.2223e-06, 5.8320e-07, 5.1621e-06, 8.5311e-05, 5.9095e-06, 1.5910e-05,\n",
       "             1.8592e-04, 1.8674e-06, 9.1434e-07, 2.2863e-05, 6.5743e-07, 1.2474e-04,\n",
       "             1.8096e-08, 7.0726e-05, 1.3395e-04, 9.9290e-06, 3.4873e-05, 8.8982e-05,\n",
       "             1.1313e-04, 1.7349e-06, 3.7001e-06, 6.4467e-06, 1.1731e-05, 4.4952e-06,\n",
       "             2.8721e-06, 5.9659e-06, 7.8314e-06, 3.3777e-05, 5.8689e-05, 1.0461e-06,\n",
       "             2.8783e-06, 1.9892e-06, 1.5817e-05, 2.6739e-06, 2.3231e-06, 1.4968e-04,\n",
       "             3.0884e-06, 1.8264e-04, 5.2529e-05, 1.7762e-06, 9.2714e-05, 3.3532e-06,\n",
       "             5.5313e-07, 2.0624e-05, 8.4807e-06, 1.5926e-05, 2.7748e-05, 2.0309e-04,\n",
       "             5.6779e-05, 2.9132e-06, 1.0748e-04, 2.6444e-06, 3.7145e-07, 5.5428e-04,\n",
       "             2.4664e-05, 3.9275e-04, 5.5924e-06, 1.3055e-04, 1.6972e-05, 2.8555e-07,\n",
       "             3.2635e-04, 4.4275e-04, 3.5330e-09, 9.5425e-07, 9.4333e-07, 1.9835e-07,\n",
       "             1.7314e-03, 5.9287e-06, 2.4177e-05, 5.4705e-04, 2.3886e-04, 4.4014e-05,\n",
       "             4.6945e-09, 1.4566e-06, 2.9420e-04, 1.7805e-04, 5.0405e-08, 3.7861e-07,\n",
       "             2.3783e-06, 2.9941e-04, 1.3877e-05, 7.7054e-06, 5.1488e-06, 4.6194e-06,\n",
       "             3.0080e-05, 5.5319e-05, 1.0235e-04, 1.8138e-07, 1.3035e-04, 2.3917e-06,\n",
       "             2.7659e-06, 9.1937e-04, 1.2633e-06, 1.9372e-04, 8.2875e-07, 1.2983e-05,\n",
       "             5.4979e-05, 2.3825e-06, 2.9583e-06, 6.5666e-05, 5.8301e-06, 3.9734e-05,\n",
       "             1.7191e-06, 1.6753e-05, 1.5685e-06, 8.9115e-04, 6.4508e-07, 2.5382e-07,\n",
       "             3.5377e-06, 1.1816e-06, 1.2670e-06, 5.1094e-06, 1.2449e-05, 4.6338e-06,\n",
       "             1.1413e-06, 7.2474e-06, 1.8524e-05, 1.3329e-04, 2.0291e-05, 5.3930e-06,\n",
       "             1.1497e-05, 5.3764e-08, 3.5680e-06, 6.1054e-07, 1.6722e-06, 4.3234e-07,\n",
       "             5.7568e-05, 1.2053e-05, 1.5589e-08, 1.2057e-03, 1.2984e-06, 6.9664e-07,\n",
       "             3.6017e-05, 2.6124e-07, 6.5666e-06, 6.7512e-06, 2.6876e-06, 1.1019e-05,\n",
       "             4.5401e-04, 3.8309e-06, 1.5600e-05, 7.9565e-05, 3.7341e-06, 5.8340e-05,\n",
       "             9.5912e-05, 5.9219e-06, 4.6498e-06, 2.0758e-04, 1.6559e-06, 1.7671e-04,\n",
       "             1.7785e-06, 1.2193e-06, 4.4744e-04, 3.7149e-05, 8.0050e-04, 8.2701e-06,\n",
       "             4.7368e-04, 1.8220e-06, 8.9708e-05, 1.0326e-04, 2.2937e-05, 7.1671e-05,\n",
       "             1.8414e-04, 3.7315e-05, 1.3718e-04, 7.4113e-06, 9.1800e-07, 7.4420e-09,\n",
       "             9.6922e-05, 4.9237e-07, 4.6491e-07, 7.9792e-06, 9.3877e-07, 7.7362e-06,\n",
       "             6.7363e-06, 8.7806e-05, 1.5152e-07, 1.1626e-04, 2.9810e-06, 1.4932e-04,\n",
       "             2.5366e-07, 2.9545e-06, 4.0395e-06, 7.0940e-05, 3.2085e-04, 3.9057e-06,\n",
       "             6.3526e-08, 3.7721e-07, 7.2139e-06, 6.2043e-06, 1.1299e-06, 2.5555e-06,\n",
       "             2.8581e-06, 2.1679e-06, 1.7666e-05, 4.8549e-06, 1.3871e-05, 3.1363e-06,\n",
       "             3.9391e-05, 6.0378e-07, 2.4033e-05, 1.9608e-06, 4.3050e-06, 7.0599e-05,\n",
       "             1.1220e-05, 3.7418e-05, 2.6772e-06, 2.7661e-04, 6.7404e-06, 4.6708e-07,\n",
       "             2.3385e-04, 1.8047e-04, 7.9724e-04, 1.5711e-06, 9.7076e-07, 1.4246e-05,\n",
       "             1.3671e-06, 2.6980e-05, 8.0523e-06, 5.4305e-07, 4.2786e-06, 2.3678e-05,\n",
       "             3.4340e-05, 1.1988e-06, 2.3509e-07, 3.5723e-06, 1.9428e-05, 1.0467e-04,\n",
       "             7.3648e-06, 3.9075e-07, 4.8398e-04, 1.3032e-05, 6.9121e-04, 1.4591e-05,\n",
       "             2.2839e-05, 1.2984e-06, 2.2642e-06, 1.9017e-09, 4.7359e-06, 7.0014e-07,\n",
       "             1.2445e-06, 1.5802e-05, 9.8808e-07, 1.2547e-04, 2.2494e-06, 4.0524e-07,\n",
       "             2.7836e-06, 1.0317e-04, 2.4209e-05, 9.7719e-06, 5.8982e-07, 1.8176e-05,\n",
       "             6.1254e-06, 1.8071e-05, 2.1158e-08, 5.9736e-05, 2.9003e-04, 2.5338e-06,\n",
       "             1.9195e-03, 7.3233e-06, 6.7718e-07, 4.8042e-07, 1.4078e-05, 4.9046e-06,\n",
       "             1.5021e-06, 7.0143e-06, 8.4186e-06, 9.1913e-09, 1.7845e-04, 2.1583e-06,\n",
       "             4.2283e-05, 5.2832e-04, 1.9814e-06, 4.4844e-06, 1.5645e-04, 2.5939e-06,\n",
       "             2.2618e-05, 2.5885e-06, 5.7566e-05, 1.6233e-05, 3.5140e-04, 1.2841e-06,\n",
       "             3.1261e-05, 7.6365e-06, 1.4675e-04, 1.3320e-06, 6.0057e-07, 3.7669e-04,\n",
       "             4.1959e-05, 2.5119e-06, 1.0836e-06, 4.6277e-07, 3.5618e-06, 1.7734e-05,\n",
       "             4.3966e-05, 2.4408e-05, 4.5966e-05, 5.1696e-06, 4.5683e-05, 1.5217e-06,\n",
       "             4.0491e-06, 5.5077e-06, 4.5853e-04, 2.6211e-06, 2.2285e-06, 3.0531e-05,\n",
       "             1.1733e-06, 1.6693e-05, 6.9456e-07, 1.0040e-05, 5.8159e-06, 1.3243e-04,\n",
       "             1.5917e-06, 1.6636e-06, 7.3962e-05, 2.1329e-05, 1.5244e-06, 1.4919e-06,\n",
       "             4.3714e-06, 2.6362e-05, 2.1240e-06, 9.4661e-07, 2.4464e-06, 9.0399e-05,\n",
       "             1.0501e-06, 1.1209e-04, 5.7246e-06, 3.6035e-05, 2.5705e-04, 6.3423e-06,\n",
       "             9.3237e-06, 5.3855e-06, 2.7391e-06, 1.3012e-06, 7.3077e-06, 9.6356e-05,\n",
       "             1.9022e-06, 9.6416e-06, 3.7680e-05, 2.4160e-06, 5.6883e-06, 2.1857e-04,\n",
       "             1.7753e-06, 1.7951e-06, 1.0578e-08, 4.1936e-06, 8.9444e-07, 6.7736e-08,\n",
       "             2.8418e-06, 1.2218e-04, 6.4852e-04, 1.9742e-04, 1.9286e-06, 1.2069e-05,\n",
       "             1.1817e-08, 1.2867e-06, 7.0718e-07, 1.9068e-04, 5.5703e-04, 3.6022e-06,\n",
       "             8.3981e-08, 9.1311e-04, 7.8974e-07, 4.4612e-07, 1.5036e-06, 8.7452e-06,\n",
       "             4.3559e-06, 1.4574e-05, 9.9973e-07, 3.3985e-04, 8.8140e-07, 5.3836e-06,\n",
       "             5.3308e-07, 4.1921e-06, 9.9922e-06, 4.0021e-07, 3.1795e-04, 8.9208e-05,\n",
       "             6.6132e-06, 3.4485e-07, 1.0390e-08, 1.9822e-04, 3.9860e-06, 7.7597e-07,\n",
       "             2.7632e-06, 1.0297e-06, 3.4789e-07, 7.6619e-05, 5.5191e-07, 4.8112e-08,\n",
       "             5.2116e-05, 2.2594e-06, 7.2191e-05, 1.9220e-06, 1.8037e-06, 8.7201e-06,\n",
       "             4.7438e-06, 3.3466e-06, 2.7967e-05, 3.8103e-04, 4.3314e-06, 4.0519e-04,\n",
       "             6.6229e-05, 5.8814e-06, 1.6313e-05, 5.6597e-06], device='mps:0')},\n",
       "    2: {'step': tensor(1290.),\n",
       "     'exp_avg': tensor([[-1.0718e-04,  3.8918e-05, -1.5764e-05,  ..., -1.8644e-06,\n",
       "               6.4072e-07, -2.2600e-06],\n",
       "             [ 3.1362e-15,  4.0261e-16, -1.2240e-16,  ..., -3.8497e-16,\n",
       "               2.3614e-16,  1.5795e-16],\n",
       "             [-1.5198e-05, -3.0221e-06, -5.6757e-06,  ...,  7.4036e-07,\n",
       "               2.9070e-06, -1.1166e-06],\n",
       "             ...,\n",
       "             [ 4.9067e-06,  1.1639e-05,  6.9482e-06,  ..., -1.2293e-06,\n",
       "              -4.0378e-06,  1.5845e-06],\n",
       "             [ 1.9801e-05,  1.5281e-05,  9.9287e-06,  ..., -1.4393e-06,\n",
       "              -4.7263e-06,  3.0909e-06],\n",
       "             [ 6.4645e-05, -5.4046e-05,  5.1000e-06,  ...,  2.9931e-06,\n",
       "               5.4464e-06, -1.3158e-06]], device='mps:0'),\n",
       "     'exp_avg_sq': tensor([[5.1131e-08, 8.8876e-08, 3.2744e-09,  ..., 2.2804e-09, 1.1052e-08,\n",
       "              2.2198e-09],\n",
       "             [5.1496e-12, 9.8380e-12, 3.1253e-12,  ..., 2.4068e-12, 2.8373e-12,\n",
       "              2.5884e-12],\n",
       "             [5.8815e-09, 2.1960e-08, 1.3594e-09,  ..., 8.5142e-10, 2.2170e-09,\n",
       "              1.2343e-09],\n",
       "             ...,\n",
       "             [6.1847e-09, 2.6102e-08, 1.1424e-09,  ..., 7.0791e-10, 2.1080e-09,\n",
       "              1.1878e-09],\n",
       "             [1.7488e-08, 7.4092e-08, 2.2342e-09,  ..., 1.4801e-09, 5.1950e-09,\n",
       "              2.8907e-09],\n",
       "             [2.9652e-08, 2.7667e-08, 9.1661e-09,  ..., 7.9119e-09, 1.6533e-08,\n",
       "              2.0247e-09]], device='mps:0')},\n",
       "    3: {'step': tensor(1290.),\n",
       "     'exp_avg': tensor([-1.1663e-03, -5.4539e-08, -1.2183e-04,  8.0411e-05, -1.1078e-08,\n",
       "              5.9960e-04,  1.1411e-04, -2.8982e-09, -7.7104e-12, -1.6575e-04,\n",
       "              4.2906e-05, -1.1061e-03, -7.7901e-04, -2.2551e-04,  9.9140e-05,\n",
       "             -1.1114e-04,  9.2399e-04,  7.5440e-04, -1.6953e-04, -8.0462e-04,\n",
       "             -3.2243e-15, -1.6319e-14,  5.9585e-04, -3.7113e-04, -5.2049e-04,\n",
       "             -1.6614e-07,  3.9281e-05, -4.5361e-13,  1.2163e-04, -5.0164e-15,\n",
       "              1.4863e-04,  5.9744e-04,  1.2878e-04, -2.0982e-14, -1.0399e-04,\n",
       "             -1.2379e-11, -1.0794e-12, -1.6446e-04, -2.7744e-04, -1.7281e-11,\n",
       "             -6.0263e-04, -7.1404e-11, -1.1822e-08, -1.3532e-04, -4.5863e-13,\n",
       "              1.3036e-04, -1.6803e-14,  5.6730e-04, -5.8418e-04,  3.6564e-05,\n",
       "              2.4893e-04, -2.1649e-19, -5.6763e-05,  6.8998e-04,  2.0978e-04,\n",
       "             -9.5937e-09,  4.0803e-20,  7.4685e-05, -8.5124e-08, -7.8061e-04,\n",
       "             -1.2914e-04, -8.0760e-04,  5.5761e-04, -6.0574e-05, -6.4912e-04,\n",
       "              5.3093e-04,  8.0668e-04,  7.4691e-16, -1.8193e-04,  4.5564e-04,\n",
       "             -7.9621e-17, -6.0857e-07, -3.9400e-04, -7.8749e-11, -4.8083e-16,\n",
       "             -8.0150e-04,  3.8341e-04, -2.0250e-14,  7.8609e-04, -3.3546e-04,\n",
       "             -1.7053e-09,  6.9262e-05, -7.1035e-04,  1.9855e-04, -3.9437e-04,\n",
       "             -1.4155e-08,  1.8775e-04, -3.1240e-04, -1.2428e-07,  1.6770e-05,\n",
       "             -3.2643e-04,  1.0684e-04, -3.0463e-08, -7.6104e-05, -9.9075e-07,\n",
       "             -2.1419e-12, -1.1550e-04,  6.5742e-13, -1.3924e-04, -1.1710e-09,\n",
       "             -2.3274e-04,  6.3856e-04,  9.9517e-05, -1.0555e-13, -8.1356e-04,\n",
       "              1.9141e-04, -3.9938e-10, -2.9785e-04, -5.6516e-04, -6.1203e-04,\n",
       "              8.0920e-05, -3.1895e-04, -1.3229e-04,  1.6783e-04,  1.1139e-04,\n",
       "              7.0096e-05, -6.2488e-04, -2.8179e-04, -4.9330e-09, -3.2129e-18,\n",
       "             -9.3113e-23,  6.6414e-04,  1.8843e-04,  9.2482e-05,  1.1336e-04,\n",
       "             -8.4933e-04,  8.1440e-04, -2.4743e-08,  5.0536e-07, -2.0279e-14,\n",
       "             -2.9702e-04, -1.3732e-09,  1.7534e-04, -2.2280e-18,  6.7348e-04,\n",
       "             -4.7767e-05, -2.7964e-04, -4.8574e-04,  3.0245e-17,  8.0263e-04,\n",
       "              5.0249e-10, -3.6889e-04,  7.6030e-04,  1.4414e-04,  1.3490e-08,\n",
       "             -3.7200e-13,  1.0638e-04, -2.1513e-11,  1.0323e-04, -6.0950e-04,\n",
       "             -9.5552e-06,  4.9298e-04, -8.1224e-04, -1.9251e-04,  2.4502e-04,\n",
       "             -7.9362e-13, -2.9678e-04, -3.5913e-04,  2.0523e-19,  1.4496e-04,\n",
       "             -2.2115e-09, -8.1720e-10,  4.8779e-05,  1.4373e-04, -2.6340e-04,\n",
       "             -3.3417e-12, -3.6521e-04,  8.2823e-04, -8.6393e-04,  5.3662e-11,\n",
       "              1.7006e-04,  3.7996e-05,  6.1179e-17,  1.2390e-04, -1.0337e-04,\n",
       "             -7.8921e-13,  5.2490e-05, -2.3262e-04, -2.9307e-04, -1.1015e-05,\n",
       "             -2.6823e-09, -1.5931e-09, -8.6874e-20, -4.9649e-11, -3.8811e-04,\n",
       "              6.2678e-04,  3.6775e-04,  8.2288e-04, -2.1143e-08,  8.8799e-05,\n",
       "             -5.0045e-04, -2.1730e-09, -8.7850e-16,  5.7964e-09,  5.3538e-04,\n",
       "             -1.5753e-13,  7.9698e-04, -3.7579e-17, -4.6949e-04, -1.4663e-04,\n",
       "             -1.2849e-12, -2.5207e-04, -3.2562e-04, -5.6700e-04,  6.5197e-04,\n",
       "              7.2170e-04,  1.3359e-04, -2.3921e-04,  4.0770e-05, -1.0706e-03,\n",
       "             -3.6785e-05, -7.9368e-04,  2.0290e-04,  1.0339e-04,  1.0869e-04,\n",
       "             -2.3170e-09,  8.0598e-04, -3.2100e-19, -3.5791e-10,  4.2506e-04,\n",
       "              3.2887e-10, -3.4656e-14, -7.1106e-10, -6.4299e-04, -3.4232e-05,\n",
       "             -8.2657e-04, -3.3227e-04, -5.3940e-04, -7.4257e-04, -3.6243e-18,\n",
       "             -2.5806e-10,  2.4782e-05, -2.5489e-04,  7.2772e-05, -2.0096e-04,\n",
       "             -5.1219e-04,  8.2880e-04, -4.4023e-04,  9.4201e-05,  8.6725e-05,\n",
       "              1.0206e-04,  1.3951e-14, -2.8946e-04,  1.4594e-15,  7.0188e-04,\n",
       "             -7.4841e-04,  6.8271e-04, -3.6768e-12, -4.9633e-04,  4.8153e-04,\n",
       "              2.5472e-13,  8.4428e-04, -2.7457e-11,  1.0262e-04, -4.5590e-16,\n",
       "             -2.3880e-09,  2.8438e-04, -2.7402e-04,  3.6106e-08,  6.6964e-04,\n",
       "              5.8603e-15,  8.8324e-04, -4.1508e-04,  7.1493e-04, -8.8804e-04,\n",
       "             -7.3769e-04, -7.0646e-04,  1.1410e-04,  1.0836e-04, -7.1834e-21,\n",
       "             -5.2710e-11,  8.5521e-04,  6.8991e-04, -3.0773e-04,  7.6335e-04,\n",
       "              1.7657e-04, -4.2699e-04, -4.1484e-17, -3.3860e-09, -2.5726e-04,\n",
       "             -7.6485e-13, -3.4687e-04, -1.9171e-04, -1.0050e-09, -6.9105e-05,\n",
       "             -8.5647e-10, -8.3008e-04,  2.0234e-04, -6.0790e-04, -2.1468e-04,\n",
       "             -3.0449e-04,  3.9763e-04, -3.4623e-04, -1.4286e-14,  2.4303e-20,\n",
       "             -2.7335e-04,  2.1951e-05,  1.4464e-23, -7.0475e-04,  1.0635e-06,\n",
       "              3.9534e-04, -8.4744e-04, -3.8190e-05, -7.6580e-04, -4.7561e-11,\n",
       "             -3.0663e-10, -8.9956e-13, -1.3914e-04, -5.4325e-04,  8.7120e-05,\n",
       "             -1.3806e-11,  8.1243e-04,  1.0949e-04,  3.5206e-11, -7.9275e-13,\n",
       "              9.1952e-04,  8.4007e-13, -1.9618e-19,  2.2443e-18, -7.9709e-04,\n",
       "             -2.8780e-04, -2.5969e-04, -7.3758e-11,  3.1239e-05,  3.7095e-09,\n",
       "             -2.7891e-04,  2.5037e-19, -2.2899e-16, -2.6151e-04,  7.8767e-04,\n",
       "             -6.4400e-21, -5.1841e-04,  2.2303e-05, -1.3996e-06, -4.5065e-04,\n",
       "             -4.2157e-17, -2.6665e-14, -4.9599e-04,  7.1214e-04, -4.7648e-04,\n",
       "             -9.4776e-08,  4.8493e-05,  6.6020e-05, -2.6461e-04,  4.1400e-04,\n",
       "             -1.5306e-18, -1.0902e-10, -4.3727e-16, -3.9069e-04, -2.7841e-14,\n",
       "             -3.0857e-04, -9.1669e-15,  5.1567e-05, -1.0000e-03,  8.0096e-04,\n",
       "             -4.2504e-04, -1.4851e-09, -1.3459e-12, -1.0981e-11, -4.1373e-16,\n",
       "             -1.9316e-04, -1.1713e-13, -2.9959e-04,  9.8628e-05,  7.6463e-13,\n",
       "             -2.4093e-04, -2.5795e-06,  1.5580e-05, -7.7616e-05,  5.7592e-05,\n",
       "              5.4327e-05, -1.3572e-04, -5.1778e-04,  6.0472e-04, -1.7482e-08,\n",
       "             -7.6418e-05, -9.8784e-10, -9.3015e-04, -1.1067e-03, -2.3963e-04,\n",
       "              9.1414e-05, -3.1976e-04, -2.0438e-11, -1.0102e-08, -2.1309e-04,\n",
       "             -8.5041e-04, -4.3908e-04, -1.6624e-13,  8.0200e-04, -3.4019e-14,\n",
       "             -2.4725e-13,  1.4060e-04, -1.1838e-15, -2.2682e-08, -2.7930e-04,\n",
       "              1.1276e-04, -3.6830e-05, -2.7175e-04,  1.4611e-04, -2.8472e-04,\n",
       "             -2.3963e-10, -3.6932e-04,  3.7057e-04, -1.4423e-15, -1.3526e-12,\n",
       "             -5.8435e-16, -5.5112e-20,  8.6107e-04, -1.4574e-10,  7.2627e-05,\n",
       "             -2.9029e-04, -7.4389e-04,  8.5506e-05, -2.1494e-10, -1.0055e-15,\n",
       "             -7.5696e-04,  2.7509e-13, -2.4339e-04,  9.3607e-05,  2.1351e-11,\n",
       "             -5.3503e-11, -5.4779e-13,  7.6966e-05, -8.3902e-12,  6.3658e-05,\n",
       "             -2.1817e-04, -6.8056e-11,  1.3486e-14,  1.1649e-05,  1.5670e-04,\n",
       "             -6.7931e-04, -5.8483e-16, -5.8222e-12, -2.6671e-20,  1.5184e-16,\n",
       "             -4.0680e-04, -5.0622e-04,  7.1010e-04,  1.4101e-04, -1.1626e-13,\n",
       "             -3.7076e-04, -4.4764e-04,  1.0909e-04,  1.1462e-04, -4.9060e-04,\n",
       "              1.2236e-04,  4.0354e-04,  6.0105e-04, -2.0168e-04, -4.2587e-12,\n",
       "              9.0311e-05,  1.5138e-04,  9.1481e-05, -3.1511e-11, -4.2742e-04,\n",
       "              3.7402e-05, -2.7029e-04,  1.3879e-04, -3.5314e-04,  1.1769e-04,\n",
       "             -6.3172e-04,  5.3390e-12, -6.5393e-10, -7.4275e-13, -1.0449e-11,\n",
       "             -1.3091e-04,  1.2670e-04, -2.1547e-17, -6.2633e-08, -2.4783e-04,\n",
       "              9.1280e-05,  1.2446e-04, -3.6686e-04,  1.4008e-13, -7.5379e-11,\n",
       "             -2.5342e-04,  2.9208e-04,  9.9039e-05, -4.5566e-04, -2.4102e-05,\n",
       "             -9.5660e-10,  9.5976e-05, -1.8522e-07,  1.2238e-04,  6.6706e-05,\n",
       "             -2.3604e-10, -1.5330e-09, -2.9331e-04, -2.1793e-11, -1.3042e-04,\n",
       "              3.4336e-05, -8.1346e-05,  2.0397e-04, -1.1710e-04, -1.1448e-06,\n",
       "             -1.4599e-07,  5.1416e-05, -4.0694e-05,  9.2937e-05,  6.6188e-04],\n",
       "            device='mps:0'),\n",
       "     'exp_avg_sq': tensor([3.9781e-05, 3.5588e-09, 6.2199e-06, 1.8900e-05, 1.1513e-08, 1.1234e-05,\n",
       "             1.9253e-05, 5.7852e-09, 2.6135e-09, 1.0334e-05, 5.2887e-06, 2.4284e-05,\n",
       "             3.3012e-05, 1.2858e-05, 3.6837e-06, 8.2606e-06, 3.3811e-05, 2.8914e-05,\n",
       "             9.9490e-06, 3.3489e-05, 1.1079e-09, 1.3491e-09, 1.2181e-05, 9.7274e-06,\n",
       "             1.5571e-05, 5.3080e-10, 4.9850e-06, 2.7755e-10, 2.7282e-05, 1.2525e-09,\n",
       "             7.9917e-06, 1.6052e-05, 8.6783e-06, 1.3907e-09, 8.7179e-06, 2.6093e-09,\n",
       "             1.9754e-09, 7.5821e-06, 3.2293e-06, 7.2782e-11, 2.3356e-05, 3.3529e-09,\n",
       "             9.7082e-09, 8.2998e-06, 3.5818e-10, 3.9450e-06, 1.3743e-09, 9.6447e-06,\n",
       "             2.9727e-05, 1.1391e-05, 8.2917e-06, 7.4370e-10, 5.6858e-06, 1.8925e-05,\n",
       "             6.4836e-06, 8.5601e-09, 6.4248e-10, 3.9172e-06, 1.6928e-08, 3.0761e-05,\n",
       "             6.9114e-06, 2.9985e-05, 1.2649e-05, 6.6954e-06, 2.2378e-05, 1.4454e-05,\n",
       "             1.8939e-05, 4.4326e-11, 5.1621e-06, 9.6539e-06, 9.7222e-10, 8.0783e-09,\n",
       "             7.0912e-06, 3.4000e-09, 1.0909e-09, 3.4336e-05, 6.9529e-06, 1.3957e-09,\n",
       "             2.7590e-05, 8.7776e-06, 4.2765e-09, 5.8536e-06, 2.9057e-05, 5.8357e-06,\n",
       "             1.4305e-05, 6.9328e-10, 5.2728e-06, 1.3245e-05, 1.3873e-08, 7.2704e-06,\n",
       "             1.0140e-05, 2.0797e-05, 1.4460e-08, 7.3817e-06, 7.9637e-11, 2.1368e-09,\n",
       "             6.3108e-06, 9.3660e-11, 5.1216e-06, 5.0683e-09, 8.3567e-06, 2.3752e-05,\n",
       "             3.7811e-06, 1.6010e-09, 3.4063e-05, 5.8403e-06, 6.5462e-10, 2.5138e-06,\n",
       "             1.6883e-05, 1.7024e-05, 1.3791e-05, 7.1242e-06, 1.0007e-05, 1.5967e-05,\n",
       "             2.0391e-05, 1.2179e-05, 3.2276e-05, 7.6307e-06, 6.4183e-09, 8.7727e-10,\n",
       "             5.4318e-10, 1.8482e-05, 5.7002e-06, 2.1335e-05, 2.6736e-05, 3.7358e-05,\n",
       "             2.4599e-05, 2.1270e-08, 3.8273e-11, 1.3748e-09, 6.1289e-06, 4.9317e-09,\n",
       "             2.3722e-05, 4.5376e-10, 1.2855e-05, 9.6153e-06, 5.6843e-06, 2.0358e-05,\n",
       "             3.1169e-10, 2.6758e-05, 3.0681e-10, 9.2073e-06, 2.8827e-05, 1.7230e-05,\n",
       "             5.3835e-10, 1.9467e-09, 2.3485e-05, 2.6594e-09, 5.3515e-06, 2.0870e-05,\n",
       "             6.6392e-06, 1.1546e-05, 3.6706e-05, 8.3399e-06, 5.3636e-06, 1.4072e-09,\n",
       "             7.0687e-06, 9.2117e-06, 1.2487e-10, 3.5284e-06, 3.1864e-10, 5.5789e-09,\n",
       "             1.1724e-05, 4.1607e-06, 5.1206e-06, 2.4150e-09, 1.1281e-05, 2.5539e-05,\n",
       "             2.6967e-05, 2.8409e-11, 5.4934e-06, 7.9325e-06, 1.7422e-10, 5.9101e-06,\n",
       "             9.5614e-06, 1.0132e-10, 1.4757e-05, 7.5115e-06, 7.6757e-06, 9.8056e-06,\n",
       "             5.6375e-09, 6.5747e-09, 4.2942e-10, 3.1916e-09, 1.1499e-05, 1.2453e-05,\n",
       "             7.1396e-06, 2.4804e-05, 1.4823e-08, 1.7596e-05, 1.8544e-05, 5.3937e-09,\n",
       "             2.6071e-10, 2.6347e-10, 4.6907e-05, 1.3503e-10, 2.5130e-05, 2.5735e-10,\n",
       "             8.0143e-06, 7.8207e-06, 2.0963e-09, 2.3196e-06, 9.1983e-06, 2.1804e-05,\n",
       "             1.8620e-05, 2.6678e-05, 1.5752e-05, 9.1848e-06, 1.1200e-05, 3.6348e-05,\n",
       "             7.4133e-06, 3.1324e-05, 4.6811e-06, 1.7641e-05, 2.7407e-06, 1.3337e-08,\n",
       "             2.5694e-05, 2.5292e-10, 4.1283e-09, 9.4879e-06, 2.5620e-10, 1.4188e-09,\n",
       "             4.9337e-09, 2.8255e-05, 1.4312e-05, 3.5563e-05, 9.0327e-06, 2.0589e-05,\n",
       "             3.3437e-05, 7.1675e-10, 3.1112e-10, 4.2986e-06, 7.0715e-06, 1.4039e-05,\n",
       "             4.2099e-06, 2.1879e-05, 2.4555e-05, 1.9116e-05, 3.1832e-06, 4.7186e-06,\n",
       "             2.4733e-05, 6.1452e-10, 8.3229e-06, 2.3654e-10, 1.4325e-05, 3.1551e-05,\n",
       "             2.0093e-05, 1.5452e-10, 2.1441e-05, 1.3298e-05, 1.4540e-10, 2.7599e-05,\n",
       "             2.5490e-09, 6.0680e-06, 6.0234e-10, 7.2577e-09, 6.4672e-06, 5.6360e-06,\n",
       "             3.8830e-06, 2.4831e-05, 6.0013e-11, 2.8913e-05, 1.3410e-05, 2.3957e-05,\n",
       "             3.0068e-05, 3.1767e-05, 2.0244e-05, 2.4422e-05, 5.5685e-06, 6.6547e-10,\n",
       "             5.3783e-10, 2.9585e-05, 1.2655e-05, 9.1563e-06, 2.7967e-05, 5.3281e-06,\n",
       "             7.4850e-06, 9.5301e-10, 7.0231e-09, 1.3069e-05, 1.0977e-09, 8.8671e-06,\n",
       "             9.0228e-06, 6.0516e-09, 1.2384e-05, 5.9398e-09, 3.6658e-05, 6.8004e-06,\n",
       "             1.8260e-05, 7.1400e-06, 5.4346e-06, 7.2360e-06, 9.2297e-06, 1.3815e-09,\n",
       "             6.3879e-10, 9.6534e-06, 5.4200e-06, 3.9080e-10, 2.7143e-05, 7.0251e-06,\n",
       "             8.5263e-06, 3.4329e-05, 7.4914e-06, 3.1866e-05, 2.5525e-09, 3.4461e-10,\n",
       "             1.8718e-09, 9.4045e-06, 2.6251e-05, 6.2272e-06, 2.5074e-09, 2.1959e-05,\n",
       "             2.7710e-05, 2.2575e-11, 2.1932e-09, 3.0662e-05, 5.4986e-11, 2.0799e-10,\n",
       "             1.4858e-10, 3.7513e-05, 2.7773e-06, 4.5111e-06, 3.4008e-09, 7.8322e-06,\n",
       "             6.2398e-10, 4.5054e-06, 3.4565e-10, 6.7155e-11, 7.5900e-06, 2.6908e-05,\n",
       "             5.7510e-10, 9.4475e-06, 5.7834e-06, 7.4037e-11, 1.8893e-05, 1.0057e-09,\n",
       "             5.3648e-11, 2.0397e-05, 2.7783e-05, 2.0256e-05, 1.0992e-08, 9.8939e-06,\n",
       "             3.2236e-06, 4.6887e-06, 8.7615e-06, 9.1760e-11, 4.8321e-10, 4.4310e-10,\n",
       "             5.6535e-06, 1.4369e-09, 6.4459e-06, 1.3277e-09, 1.8845e-05, 3.9320e-05,\n",
       "             2.1059e-05, 1.3591e-05, 4.6828e-09, 2.7595e-10, 2.0631e-09, 1.0633e-10,\n",
       "             8.7762e-06, 1.7303e-09, 6.5260e-06, 1.8727e-05, 6.1409e-11, 4.7829e-06,\n",
       "             1.7367e-10, 4.3425e-06, 6.8622e-06, 1.2987e-05, 7.2599e-06, 8.4828e-06,\n",
       "             1.8307e-05, 1.8264e-05, 1.3470e-08, 8.4928e-06, 8.0745e-09, 3.2787e-05,\n",
       "             4.0455e-05, 4.4715e-06, 2.4025e-05, 8.6172e-06, 2.4748e-09, 7.3951e-10,\n",
       "             1.3128e-05, 3.4216e-05, 1.4236e-05, 1.6520e-09, 2.3052e-05, 8.4212e-10,\n",
       "             1.5918e-09, 2.8797e-06, 1.1185e-09, 1.2974e-08, 6.3785e-06, 2.6359e-05,\n",
       "             8.4818e-06, 6.4694e-06, 5.0123e-06, 7.3159e-06, 2.8605e-09, 1.4993e-05,\n",
       "             9.1818e-06, 1.0780e-09, 1.8789e-09, 1.1145e-09, 3.4003e-10, 3.1417e-05,\n",
       "             8.3476e-11, 1.6636e-05, 5.7057e-06, 3.0941e-05, 2.0160e-05, 3.7719e-09,\n",
       "             1.1509e-09, 3.2791e-05, 1.0411e-10, 3.9111e-06, 1.5381e-05, 1.3435e-10,\n",
       "             4.0887e-09, 1.4902e-10, 1.4537e-05, 2.3607e-09, 1.3681e-05, 4.8644e-06,\n",
       "             1.0269e-10, 2.5538e-10, 7.8404e-06, 3.7947e-06, 2.9413e-05, 1.1669e-09,\n",
       "             2.2216e-09, 5.9524e-10, 2.5235e-10, 1.0568e-05, 2.1016e-05, 2.5350e-05,\n",
       "             6.7970e-06, 1.6684e-09, 1.0376e-05, 2.1787e-05, 5.2691e-06, 1.5209e-05,\n",
       "             2.4230e-05, 5.1730e-06, 9.3616e-06, 1.5165e-05, 5.1421e-06, 3.6516e-09,\n",
       "             1.2283e-05, 3.5450e-06, 1.5985e-05, 4.2322e-10, 1.4809e-05, 6.3522e-06,\n",
       "             3.5379e-06, 3.3495e-06, 6.2351e-06, 2.7223e-05, 3.1737e-05, 3.2049e-10,\n",
       "             3.7232e-10, 1.8305e-09, 2.6197e-09, 4.1064e-06, 1.8961e-05, 5.4720e-10,\n",
       "             1.9954e-08, 5.4100e-06, 4.6978e-06, 2.4145e-05, 4.9931e-06, 5.6157e-10,\n",
       "             1.9836e-10, 3.0260e-06, 7.0562e-06, 1.9052e-05, 1.3521e-05, 5.3411e-06,\n",
       "             5.0635e-09, 4.6377e-06, 4.4292e-08, 2.0696e-05, 1.1997e-05, 3.5764e-10,\n",
       "             6.6922e-09, 1.3684e-05, 3.0055e-09, 8.5186e-06, 7.7137e-08, 8.8468e-06,\n",
       "             6.4946e-06, 9.7942e-06, 1.3295e-05, 1.2815e-08, 7.7195e-06, 7.2259e-06,\n",
       "             1.9926e-05, 2.4428e-05], device='mps:0')},\n",
       "    4: {'step': tensor(1290.),\n",
       "     'exp_avg': tensor([[-8.0094e-04,  4.1464e-08, -2.7392e-04,  ...,  1.4586e-04,\n",
       "               2.7439e-04,  1.8778e-04],\n",
       "             [ 2.5687e-04, -1.6281e-07,  1.3035e-04,  ..., -2.7798e-04,\n",
       "              -4.8859e-04,  8.9639e-05],\n",
       "             [ 4.1261e-04,  1.1465e-09,  4.9410e-05,  ...,  9.1592e-05,\n",
       "               9.6659e-05, -3.5492e-04]], device='mps:0'),\n",
       "     'exp_avg_sq': tensor([[2.1850e-06, 7.1460e-09, 6.3065e-06,  ..., 3.4664e-06, 4.0759e-06,\n",
       "              6.7043e-06],\n",
       "             [9.4138e-07, 6.0516e-09, 2.3633e-06,  ..., 3.7400e-06, 4.7807e-06,\n",
       "              1.3479e-06],\n",
       "             [9.8027e-07, 1.4739e-09, 5.0419e-06,  ..., 9.0519e-07, 7.7741e-07,\n",
       "              7.9796e-06]], device='mps:0')},\n",
       "    5: {'step': tensor(1290.),\n",
       "     'exp_avg': tensor([-1.1757e-03, -2.8802e-05,  1.2568e-03], device='mps:0'),\n",
       "     'exp_avg_sq': tensor([0.0005, 0.0003, 0.0003], device='mps:0')}},\n",
       "   'param_groups': [{'lr': 0.001,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0.001,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'capturable': False,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'params': [0, 1, 2, 3, 4, 5]}]}],\n",
       " 'lr_schedulers': [],\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'input_shape': 26439,\n",
       "  'output_shape': 3,\n",
       "  'weight_decay': 0.001}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.load('/Users/pranavjha/Library/CloudStorage/GoogleDrive-pranajh7@gmail.com/My Drive/Projects/applied_theories/sentiment analysis/checkpoints/ohe/epoch=9-val_f1score=0.683.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc1583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43061734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
